{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/homebrew/lib/python3.9/site-packages (from fasttext) (65.4.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.9/site-packages (from fasttext) (1.22.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[151 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/FastText.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/util.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating var\n",
      "  \u001b[31m   \u001b[0m creating var/folders\n",
      "  \u001b[31m   \u001b[0m creating var/folders/s3\n",
      "  \u001b[31m   \u001b[0m creating var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn\n",
      "  \u001b[31m   \u001b[0m creating var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpp7byioas.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpp7byioas.o -stdlib=libc++\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:08.909 xcodebuild[9093:2402976] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:08.935 xcodebuild[9093:2402976] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x12ba710d0>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x14ae0c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001024493d0\n",
      "  \u001b[31m   \u001b[0m   1  0x0000000102448aac\n",
      "  \u001b[31m   \u001b[0m   2  0x0000000102448c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x00000001022f726c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001022bd0d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001022bb4e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x000000010248d54c\n",
      "  \u001b[31m   \u001b[0m   9  0x0000000102469470\n",
      "  \u001b[31m   \u001b[0m  10  0x00000001022bb380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001022bb5a0\n",
      "  \u001b[31m   \u001b[0m  12  0x000000010337f2ec\n",
      "  \u001b[31m   \u001b[0m  13  0x000000010337eae0\n",
      "  \u001b[31m   \u001b[0m  14  0x000000010337e1e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000100d1c324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000100aade0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9095 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp2w4_qwe5.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp2w4_qwe5.o -stdlib=libc++ -mmacosx-version-min=10.7\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:09.699 xcodebuild[9099:2403021] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:09.721 xcodebuild[9099:2403021] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x11eb951e0>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x12560c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001061b13d0\n",
      "  \u001b[31m   \u001b[0m   1  0x00000001061b0aac\n",
      "  \u001b[31m   \u001b[0m   2  0x00000001061b0c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x000000010605f26c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001060250d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001060234e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x00000001061f554c\n",
      "  \u001b[31m   \u001b[0m   9  0x00000001061d1470\n",
      "  \u001b[31m   \u001b[0m  10  0x0000000106023380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001060235a0\n",
      "  \u001b[31m   \u001b[0m  12  0x00000001070e72ec\n",
      "  \u001b[31m   \u001b[0m  13  0x00000001070e6ae0\n",
      "  \u001b[31m   \u001b[0m  14  0x00000001070e61e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000104a84324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000104815e0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9101 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 168, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/wheel/bdist_wheel.py\", line 299, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('build')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 131, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(\n",
      "  \u001b[31m   \u001b[0m RuntimeError: libc++ is needed! Failed to compile with -stdlib=libc++ -mmacosx-version-min=10.7 and -stdlib=libc++.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for fasttext\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for fasttext ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for fasttext\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[150 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/FastText.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/util.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp5n4fjd87.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp5n4fjd87.o -stdlib=libc++\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:11.927 xcodebuild[9105:2403147] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:11.947 xcodebuild[9105:2403147] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x10c42b740>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x12e60c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001028953d0\n",
      "  \u001b[31m   \u001b[0m   1  0x0000000102894aac\n",
      "  \u001b[31m   \u001b[0m   2  0x0000000102894c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x000000010274326c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001027090d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001027074e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x00000001028d954c\n",
      "  \u001b[31m   \u001b[0m   9  0x00000001028b5470\n",
      "  \u001b[31m   \u001b[0m  10  0x0000000102707380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001027075a0\n",
      "  \u001b[31m   \u001b[0m  12  0x00000001037cb2ec\n",
      "  \u001b[31m   \u001b[0m  13  0x00000001037caae0\n",
      "  \u001b[31m   \u001b[0m  14  0x00000001037ca1e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000101168324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000100ef9e0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9107 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpm6wmyxcx.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpm6wmyxcx.o -stdlib=libc++ -mmacosx-version-min=10.7\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:12.642 xcodebuild[9109:2403170] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:12.662 xcodebuild[9109:2403170] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x13b91c5e0>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x15b60c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001043313d0\n",
      "  \u001b[31m   \u001b[0m   1  0x0000000104330aac\n",
      "  \u001b[31m   \u001b[0m   2  0x0000000104330c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x00000001041df26c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001041a50d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001041a34e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x000000010437554c\n",
      "  \u001b[31m   \u001b[0m   9  0x0000000104351470\n",
      "  \u001b[31m   \u001b[0m  10  0x00000001041a3380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001041a35a0\n",
      "  \u001b[31m   \u001b[0m  12  0x00000001051b32ec\n",
      "  \u001b[31m   \u001b[0m  13  0x00000001051b2ae0\n",
      "  \u001b[31m   \u001b[0m  14  0x00000001051b21e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000102a80324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000102a31e0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9111 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 168, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/command/install.py\", line 68, in run\n",
      "  \u001b[31m   \u001b[0m     return orig.install.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/install.py\", line 698, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('build')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 131, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(\n",
      "  \u001b[31m   \u001b[0m RuntimeError: libc++ is needed! Failed to compile with -stdlib=libc++ -mmacosx-version-min=10.7 and -stdlib=libc++.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m fasttext\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytorch-crf in /opt/homebrew/lib/python3.9/site-packages (0.7.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /opt/homebrew/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (2022.8.2)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.9/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/lib/python3.9/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/homebrew/lib/python3.9/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/homebrew/lib/python3.9/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sklearn in /opt/homebrew/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.9/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "!pip install pytorch-crf\n",
    "!pip install datasets\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import torch\n",
    "import random\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchcrf import CRF\n",
    "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
    "from typing import List, Tuple, AnyStr\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from datasets import load_dataset, load_metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d91410411844699a3b644962ea1457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fb5eea1df9414e9271ba532413724d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset conll2003/conll2003 (download: 959.94 KiB, generated: 9.78 MiB, post-processed: Unknown size, total: 10.72 MiB) to /Users/christianjensen/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d1b9e2c3bf4e388a5626cf943af6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e87a5dfe16c4383aad34f63876a5c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a62915969d4860a5635b4c968a1d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4925333597474815bea9b5169d41fbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conll2003 downloaded and prepared to /Users/christianjensen/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a1b899112e4dd2b5ac1055bb13b078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset(\"conll2003\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce down to our vocabulary and word embeddings\n",
    "def load_vectors(fname, vocabulary):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    tag_names = datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "    final_vocab = tag_names + ['[PAD]', '[UNK]', '[BOS]', '[EOS]']\n",
    "    final_vectors = [np.random.normal(size=(300,)) for _ in range(len(final_vocab))]\n",
    "    for j,line in enumerate(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in vocabulary or len(final_vocab) < 30000:\n",
    "            final_vocab.append(tokens[0])\n",
    "            final_vectors.append(np.array(list(map(float, tokens[1:]))))\n",
    "    return final_vocab, np.vstack(final_vectors)\n",
    "\n",
    "class FasttextTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = {}\n",
    "        for j,l in enumerate(vocabulary):\n",
    "            self.vocab[l.strip()] = j\n",
    "\n",
    "    def encode(self, text):\n",
    "        # Text is assumed to be tokenized\n",
    "        return [self.vocab[t] if t in self.vocab else self.vocab['[UNK]'] for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocabulary:  40630\n"
     ]
    }
   ],
   "source": [
    "vocabulary = (set([t for s in datasets['train'] for t in s['tokens']]) | set([t for s in datasets['validation'] for t in s['tokens']]))\n",
    "vocabulary, pretrained_embeddings = load_vectors('wiki-news-300d-1M.vec', vocabulary)\n",
    "print('size of vocabulary: ', len(vocabulary))\n",
    "tokenizer = FasttextTokenizer(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    input_ids = [tokenizer.encode(i['tokens']) for i in input_data]\n",
    "    seq_lens = [len(i) for i in input_ids]\n",
    "    labels = [i['ner_tags'] for i in input_data]\n",
    "\n",
    "    max_length = max([len(i) for i in input_ids])\n",
    "\n",
    "    input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\n",
    "    labels = [(i + [0] * (max_length - len(i))) for i in labels] # 0 is the id of the O tag\n",
    "\n",
    "    assert (all(len(i) == max_length for i in input_ids))\n",
    "    assert (all(len(i) == max_length for i in labels))\n",
    "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[36231,    48,    10, 33561, 30770,  8120, 31121, 21803,    10, 36750,\n",
       "             15]]),\n",
       " tensor([11]),\n",
       " tensor([[0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dl = DataLoader(datasets['validation'], batch_size=1, shuffle=False, collate_fn=collate_batch_bilstm, num_workers=0)\n",
    "next(iter(dev_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['CRICKET', '-', 'LEICESTERSHIRE', 'TAKE', 'OVER', 'AT', 'TOP', 'AFTER', 'INNINGS', 'VICTORY', '.'], 'pos_tags': [22, 8, 22, 22, 15, 22, 22, 22, 22, 21, 7], 'chunk_tags': [11, 0, 11, 12, 13, 11, 12, 12, 12, 12, 0], 'ner_tags': [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "(tensor([[36231,    48,    10, 33561, 30770,  8120, 31121, 21803,    10, 36750,\n",
      "            15]]), tensor([11]), tensor([[0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print(datasets['validation'][0])\n",
    "print(collate_batch_bilstm([datasets['validation'][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic BiLSTM-CRF network\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_embeddings: torch.tensor,\n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1,\n",
    "            n_classes: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializer for basic BiLSTM network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained BPE embeddings\n",
    "        :param lstm_dim: The dimensionality of the BiLSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        :param n_classes: The number of output classes\n",
    "        \"\"\"\n",
    "\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "\n",
    "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
    "        # The components are an embedding layer, a 2 layer BiLSTM, and a feed-forward output layer\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
    "            'bilstm': nn.LSTM(\n",
    "                pretrained_embeddings.shape[1],\n",
    "                lstm_dim,\n",
    "                2,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_prob,\n",
    "                bidirectional=True),\n",
    "            'ff': nn.Linear(2*lstm_dim, n_classes),\n",
    "            'CRF': CRF(n_classes, batch_first=True)\n",
    "        })\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Initialize the weights of the model\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['bilstm'].named_parameters()) + \\\n",
    "                     list(self.model['ff'].named_parameters())\n",
    "        for n,p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "    def forward(self, inputs, input_lens, labels = None):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :param labels: (b) The label of each sample\n",
    "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings (b x sl x edim)\n",
    "        embeds = self.model['embeddings'](inputs)\n",
    "\n",
    "        # Pack padded: This is necessary for padded batches input to an RNN\n",
    "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
    "            embeds,\n",
    "            input_lens.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # Pass the packed sequence through the BiLSTM\n",
    "        lstm_out, hidden = self.model['bilstm'](lstm_in)\n",
    "\n",
    "        # Unpack the packed sequence --> (b x sl x 2*lstm_dim)\n",
    "        lstm_out,_ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        # Get emissions (b x seq_len x n_classes)\n",
    "        emissions = self.model['ff'](lstm_out)\n",
    "        outputs = (emissions,)\n",
    "        if labels is not None:\n",
    "            mask = (inputs != 0)\n",
    "            # log-likelihood from the CRF\n",
    "            log_likelihood = self.model['CRF'](emissions, labels, mask=mask, reduction='token_mean')\n",
    "            outputs = (-log_likelihood,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def decode(self, emissions, mask):\n",
    "        \"\"\"\n",
    "        Given a set of emissions and a mask, decode the sequence\n",
    "        \"\"\"\n",
    "        return self.model['CRF'].decode(emissions, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module, \n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    n_epochs: int, \n",
    "    device: torch.device,\n",
    "    scheduler=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    The main training loop which will optimize a given model on a given dataset\n",
    "    :param model: The model being optimized\n",
    "    :param train_dl: The training dataset\n",
    "    :param valid_dl: A validation dataset\n",
    "    :param optimizer: The optimizer used to update the model parameters\n",
    "    :param n_epochs: Number of epochs to train for\n",
    "    :param device: The device to train on\n",
    "    :return: (model, losses) The best model and the losses per iteration\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep track of the loss and best accuracy\n",
    "    losses = []\n",
    "    learning_rates = []\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    # Iterate through epochs\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        loss_epoch = []\n",
    "\n",
    "        #Iterate through each batch in the dataloader\n",
    "        for batch in tqdm(train_dl):\n",
    "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
    "            # things like dropout and layer normalization\n",
    "            model.train()\n",
    "\n",
    "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
    "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
    "            # zero them out\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Place each tensor on the GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            seq_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            # Pass the inputs through the model, get the current loss and logits\n",
    "            loss, logits = model(input_ids, seq_lens, labels=labels)\n",
    "            losses.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "            # Calculate all of the gradients and weight updates for the model\n",
    "            loss.backward()\n",
    "\n",
    "            # Optional: clip gradients\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Finally, update the weights of the model\n",
    "            optimizer.step()\n",
    "            if scheduler != None:\n",
    "                scheduler.step()\n",
    "                learning_rates.append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        #gc.collect()\n",
    "\n",
    "        # Perform inline evaluation at the end of the epoch\n",
    "        f1 = evaluate(model, valid_dl)\n",
    "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
    "\n",
    "        # Keep track of the best model based on the accuracy\n",
    "        if f1 > best_f1:\n",
    "            torch.save(model.state_dict(), 'best_model')\n",
    "            best_f1 = f1\n",
    "            #gc.collect()\n",
    "\n",
    "    return losses, learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, valid_dl: DataLoader):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given dataset\n",
    "    :param model: The model under evaluation\n",
    "    :param valid_dl: A `DataLoader` reading validation data\n",
    "    :return: The accuracy of the model on the dataset\n",
    "    \"\"\"\n",
    "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like \n",
    "    # layer normalization and dropout\n",
    "    model.eval()\n",
    "    labels_all = []\n",
    "    logits_all = []\n",
    "    tags_all = []\n",
    "\n",
    "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            seq_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            logits = model(input_ids, seq_lens, labels=labels)[-1]\n",
    "            mask = (input_ids != 0)\n",
    "            labels_all.extend([l for seq,samp in zip(list(labels.detach().cpu().numpy()), input_ids) for l,i in zip(seq,samp) if i != 0])\n",
    "            logits_all.extend(list(logits.detach().cpu().numpy()))\n",
    "\n",
    "            tags = model.decode(logits, mask)\n",
    "            tags_all.extend([t for seq in tags for t in seq])\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, tags_all, average='macro')\n",
    "    print(confusion_matrix(labels_all, tags_all))\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dim = 128\n",
    "dropout_prob = 0.1\n",
    "batch_size = 8\n",
    "lr = 1e-2\n",
    "n_epochs = 1\n",
    "n_workers = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "# Create the model\n",
    "model = BiLSTM_CRF(\n",
    "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
    "    lstm_dim=lstm_dim, \n",
    "    dropout_prob=dropout_prob, \n",
    "    n_classes=len(datasets[\"train\"].features[f\"ner_tags\"].feature.names)\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb83a674e344ceae7c3742646cd942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2acba2ba994faa81c912674182bd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42615    33     5    28    33    13     1    17    14]\n",
      " [   15  1781     8     3     2    29     0     4     0]\n",
      " [   19    16  1260     0     3     0     8     0     1]\n",
      " [   37    29     1  1184    22    44     0    24     0]\n",
      " [   36     2     5     5   655     5    23     2    18]\n",
      " [   21     9     1    30     3  1758     4    11     0]\n",
      " [    5     0     0     1    10     3   230     0     8]\n",
      " [   59    12     0    40     2    18     0   784     7]\n",
      " [   31     2     5     0    23     2     9    13   261]]\n",
      "Validation F1: 0.9096205577773231, train loss: 0.08876545788642817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(datasets['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "valid_dl = DataLoader(datasets['validation'], batch_size=len(datasets['validation']), collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_dl)*n_epochs, cycle_momentum=False)\n",
    "\n",
    "# Train\n",
    "losses, learning_rates = train(model, train_dl, valid_dl, optimizer, n_epochs, device, scheduler)\n",
    "model.load_state_dict(torch.load('best_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b874478bdf444aaa7ee89fe8885076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37864   143    12    83    89    30    15    48    39]\n",
      " [  109  1426    13    31    16    19     1     1     1]\n",
      " [  119     9   992     0    29     0     7     0     0]\n",
      " [  132    82     0  1281    41    86     0    39     0]\n",
      " [   52     3     6     8   709     2    38     1    16]\n",
      " [   94    24     1    56     6  1460     1    25     1]\n",
      " [   30     0     5     0    23     2   196     0     1]\n",
      " [   90    18     0    31     5    21     0   529     8]\n",
      " [   37     1     4     1    21     0     8     5   139]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8270875092908035"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataLoader(datasets['test'], batch_size=len(datasets['test']), collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "\n",
    "evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SOCCER', 'O', 'O'), ('-', 'O', 'O'), ('JAPAN', 'B-LOC', 'B-LOC'), ('GET', 'O', 'O'), ('LUCKY', 'B-PER', 'O'), ('WIN', 'O', 'O'), (',', 'O', 'O'), ('CHINA', 'B-LOC', 'B-PER'), ('IN', 'O', 'O'), ('SURPRISE', 'B-PER', 'O'), ('DEFEAT', 'O', 'O'), ('.', 'O', 'O')]\n",
      "[('AL-AIN', 'B-LOC', 'B-LOC'), (',', 'O', 'O'), ('United', 'B-LOC', 'B-LOC'), ('Arab', 'I-LOC', 'I-LOC'), ('Emirates', 'I-LOC', 'I-LOC'), ('1996-12-06', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "examples = [0, 2]\n",
    "for ex in examples:\n",
    "    samples = [b.to(device) for b in next(iter(test_dl))]\n",
    "\n",
    "    # Get the emissions. These are basically p(y|x) for each token x,\n",
    "    # which will be input to the CRF a decoded with the help of p(y_t|y_{t-1})\n",
    "    (emissions,) = model(samples[0], samples[1])\n",
    "    mask = (samples[0] != 0)\n",
    "\n",
    "    tags = model.decode(emissions, mask)\n",
    "\n",
    "    print([(tok, datasets[\"train\"].features[f\"ner_tags\"].feature.names[tag], datasets[\"train\"].features[f\"ner_tags\"].feature.names[gold_tag]) \n",
    "    for tok,tag, gold_tag in zip(datasets['test'][ex]['tokens'], tags[ex], datasets['test'][ex]['ner_tags'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: 0.09887360036373138\n",
      "B-PER: 0.02634219266474247\n",
      "I-PER: 0.5255393981933594\n",
      "B-ORG: 0.06796828657388687\n",
      "I-ORG: 0.022453922778367996\n",
      "B-LOC: 0.08492299914360046\n",
      "I-LOC: 0.0441599115729332\n",
      "B-MISC: 0.0854225680232048\n",
      "I-MISC: 0.04431707412004471\n"
     ]
    }
   ],
   "source": [
    "b_per_id = datasets[\"train\"].features[f\"ner_tags\"].feature.names.index(\"B-PER\")\n",
    "transitions = model.model[\"CRF\"].transitions[b_per_id].detach().to(\"cpu\")\n",
    "transitions = torch.softmax(transitions, 0).numpy()\n",
    "for idx, tag in enumerate(datasets[\"train\"].features[f\"ner_tags\"].feature.names):\n",
    "    print(f\"{tag}: {transitions[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Encoder model.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "            pretrained_embeddings: torch.tensor, \n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initializer for EncoderRNN network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
    "        :param lstm_dim: The dimensionality of the LSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        \"\"\"\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
    "        # The components are an embedding layer, and an LSTM layer.\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
    "            'lstm': nn.LSTM(pretrained_embeddings.shape[1], lstm_dim, 2, batch_first=True, bidirectional=True),\n",
    "        })\n",
    "        # Initialize the weights of the model\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['lstm'].named_parameters())\n",
    "        for n, p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "    def forward(self, inputs, input_lens):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :return: (lstm output state, lstm hidden state) \n",
    "        \"\"\"\n",
    "        embeds = self.model['embeddings'](inputs)\n",
    "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
    "                    embeds,\n",
    "                    input_lens.cpu(),\n",
    "                    batch_first=True,\n",
    "                    enforce_sorted=False\n",
    "                )\n",
    "        lstm_out, hidden_states = self.model['lstm'](lstm_in)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        return lstm_out, hidden_states\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Decoder model.\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_embeddings: torch.tensor, \n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1,\n",
    "            n_classes: int = 2):\n",
    "        \"\"\"\n",
    "        Initializer for DecoderRNN network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
    "        :param lstm_dim: The dimensionality of the LSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        :param n_classes: Number of prediction classes\n",
    "        \"\"\"\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
    "        # The components are an embedding layer, a LSTM layer, and a feed-forward output layer\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
    "            'lstm': nn.LSTM(pretrained_embeddings.shape[1], lstm_dim, 2, bidirectional=True, batch_first=True),\n",
    "            'nn': nn.Linear(lstm_dim*2, n_classes),\n",
    "        })\n",
    "        # Initialize the weights of the model\n",
    "        self._init_weights()      \n",
    "\n",
    "    def forward(self, inputs, hidden, input_lens):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param hidden: (b) The hidden state of the previous step\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :return: (output predictions, lstm hidden states) the hidden states will be used as input at the next step\n",
    "        \"\"\"\n",
    "        embeds = self.model['embeddings'](inputs)\n",
    "\n",
    "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
    "                    embeds,\n",
    "                    input_lens.cpu(),\n",
    "                    batch_first=True,\n",
    "                    enforce_sorted=False\n",
    "                )\n",
    "        lstm_out, hidden_states = self.model['lstm'](lstm_in, hidden)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        output = self.model['nn'](lstm_out)\n",
    "        return output, hidden_states\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['lstm'].named_parameters()) + list(self.model['nn'].named_parameters())\n",
    "        for n, p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "# Define the model\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Seq2Seq network\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_embeddings: torch.tensor,\n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1,\n",
    "            n_classes: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializer for basic Seq2Seq network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
    "        :param lstm_dim: The dimensionality of the LSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        :param n_classes: The number of output classes\n",
    "        \"\"\"\n",
    "\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        # We'll define the network in a ModuleDict, which consists of an encoder and a decoder\n",
    "        self.model = nn.ModuleDict({\n",
    "            'encoder': EncoderRNN(pretrained_embeddings, lstm_dim, dropout_prob),\n",
    "            'decoder': DecoderRNN(pretrained_embeddings, lstm_dim, dropout_prob, n_classes),\n",
    "        })\n",
    "        self.loss = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.5]+[1]*(len(datasets[\"train\"].features[f\"ner_tags\"].feature.names)-1)).to(device))\n",
    "\n",
    "\n",
    "    def forward(self, inputs, input_lens, labels=None):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model. \n",
    "        For the Seq2Seq model this includes 1) encoding the whole input text, \n",
    "        and running *target_length* decoding steps to predict the tag of each token.\n",
    "\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :param labels: (b) The label of each sample\n",
    "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings (b x sl x embedding dim)\n",
    "        encoder_output, encoder_hidden = self.model['encoder'](inputs, input_lens)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = torch.tensor([tokenizer.encode(['[BOS]'])]*inputs.shape[0], device=device)\n",
    "        target_length = labels.size(1)\n",
    "\n",
    "        loss = None\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = self.model['decoder'](\n",
    "                decoder_input, decoder_hidden, torch.tensor([1]*inputs.shape[0]))\n",
    "\n",
    "            if loss == None:   \n",
    "                loss = self.loss(decoder_output.squeeze(1), labels[:, di])\n",
    "            else:\n",
    "                loss += self.loss(decoder_output.squeeze(1), labels[:, di])\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            decoder_input = labels[:, di].unsqueeze(-1) \n",
    "\n",
    "        return loss / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module, \n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    n_epochs: int, \n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    The main training loop which will optimize a given model on a given dataset\n",
    "    :param model: The model being optimized\n",
    "    :param train_dl: The training dataset\n",
    "    :param valid_dl: A validation dataset\n",
    "    :param optimizer: The optimizer used to update the model parameters\n",
    "    :param n_epochs: Number of epochs to train for\n",
    "    :param device: The device to train on\n",
    "    :return: (model, losses) The best model and the losses per iteration\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep track of the loss and best accuracy\n",
    "    losses = []\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    # Iterate through epochs\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        loss_epoch = []\n",
    "\n",
    "        #Iterate through each batch in the dataloader\n",
    "        for batch in tqdm(train_dl):\n",
    "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
    "            # things like dropout and layer normalization\n",
    "            model.train()\n",
    "\n",
    "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
    "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
    "            # zero them out\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Place each tensor on the GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            labels = batch[2]\n",
    "            input_lens = batch[1]\n",
    "\n",
    "            # Pass the inputs through the model, get the current loss and logits\n",
    "            loss = model(input_ids, labels=labels, input_lens=input_lens)\n",
    "            losses.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "            # Calculate all of the gradients and weight updates for the model\n",
    "            loss.backward()\n",
    "\n",
    "            # Optional: clip gradients\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Finally, update the weights of the model\n",
    "            optimizer.step()\n",
    "\n",
    "        # Perform inline evaluation at the end of the epoch\n",
    "        f1 = evaluate(model, valid_dl)\n",
    "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
    "\n",
    "        # Keep track of the best model based on the accuracy\n",
    "        if f1 > best_f1:\n",
    "            torch.save(model.state_dict(), 'best_model')\n",
    "            best_f1 = f1\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "def decode(model, inputs, input_lens, labels=None, beam_size=2):\n",
    "    \"\"\"\n",
    "    Decoding/predicting the labels for an input text by running beam search.\n",
    "\n",
    "    :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "    :param input_lens: (b) The length of each input sequence\n",
    "    :param labels: (b) The label of each sample\n",
    "    :param beam_size: the size of the beam \n",
    "    :return: predicted sequence of labels\n",
    "    \"\"\"\n",
    "\n",
    "    assert inputs.shape[0] == 1\n",
    "    # first, encode the input text\n",
    "    encoder_output, encoder_hidden = model.model['encoder'](inputs, input_lens)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # the decoder starts generating after the Begining of Sentence (BOS) token\n",
    "    decoder_input = torch.tensor([tokenizer.encode(['[BOS]',]),], device=device)\n",
    "    target_length = labels.shape[1]\n",
    "    \n",
    "    # we will use heapq to keep top best sequences so far sorted in heap_queue \n",
    "    # these will be sorted by the first item in the tuple\n",
    "    heap_queue = []\n",
    "    heap_queue.append((torch.tensor(0), tokenizer.encode(['[BOS]']), decoder_input, decoder_hidden))\n",
    "\n",
    "    # Beam Decoding\n",
    "    for _ in range(target_length):\n",
    "        # print(\"next len\")\n",
    "        new_items = []\n",
    "        # for each item on the beam\n",
    "        for j in range(len(heap_queue)): \n",
    "            # 1. remove from heap\n",
    "            score, tokens, decoder_input, decoder_hidden = heapq.heappop(heap_queue)\n",
    "            # 2. decode one more step\n",
    "            decoder_output, decoder_hidden = model.model['decoder'](\n",
    "                decoder_input, decoder_hidden, torch.tensor([1]))\n",
    "            decoder_output = softmax(decoder_output)\n",
    "            # 3. get top-k predictions\n",
    "            best_idx = torch.argsort(decoder_output[0], descending=True)[0]\n",
    "            # print(decoder_output)\n",
    "            # print(best_idx)\n",
    "            for i in range(beam_size):\n",
    "                decoder_input = torch.tensor([[best_idx[i]]], device=device)\n",
    "                \n",
    "                new_items.append((score + decoder_output[0,0, best_idx[i]],\n",
    "                                  tokens + [best_idx[i].item()], \n",
    "                                  decoder_input, \n",
    "                                  decoder_hidden))\n",
    "        # add new sequences to the heap\n",
    "        for item in new_items:\n",
    "          # print(item)\n",
    "            heapq.heappush(heap_queue, item)\n",
    "        # remove sequences with lowest score (items are sorted in descending order)\n",
    "        while len(heap_queue) > beam_size:\n",
    "            heapq.heappop(heap_queue)\n",
    "          \n",
    "    final_sequence = heapq.nlargest(1, heap_queue)[0]\n",
    "    assert labels.shape[1] == len(final_sequence[1][1:])\n",
    "    return final_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, valid_dl: DataLoader, beam_size:int = 1):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given dataset\n",
    "    :param model: The model under evaluation\n",
    "    :param valid_dl: A `DataLoader` reading validation data\n",
    "    :return: The accuracy of the model on the dataset\n",
    "    \"\"\"\n",
    "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like \n",
    "    # layer normalization and dropout\n",
    "    model.eval()\n",
    "    labels_all = []\n",
    "    logits_all = []\n",
    "    tags_all = []\n",
    "\n",
    "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            input_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            best_seq = decode(model, input_ids, input_lens, labels=labels, beam_size=beam_size)\n",
    "            mask = (input_ids != 0)\n",
    "            labels_all.extend([l for seq,samp in zip(list(labels.detach().cpu().numpy()), input_ids) for l,i in zip(seq,samp) if i != 0])\n",
    "            tags_all += best_seq[1][1:]\n",
    "            # print(best_seq[1][1:], labels)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, tags_all, average='macro')\n",
    "    print(confusion_matrix(labels_all, tags_all))\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dim = 300\n",
    "dropout_prob = 0.1\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "n_epochs = 1\n",
    "n_workers = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "# Create the model\n",
    "model = Seq2Seq(\n",
    "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
    "    lstm_dim=lstm_dim, \n",
    "    dropout_prob=dropout_prob, \n",
    "    n_classes=len(datasets[\"train\"].features[f\"ner_tags\"].feature.names)\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6c6b339cd44a2a8de019f3fd7cd3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba04efb6e498412ab309ef0bf4101292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/3250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40390   187   165   124  1324   259   229    22    59]\n",
      " [  905   574    99    30   141    60    27     3     3]\n",
      " [  685    40   394    13   136    28     8     0     3]\n",
      " [  667    13     5   506    99    25     9    16     1]\n",
      " [  472     7    10    26   205    10    18     1     2]\n",
      " [  956     7    10   121   115   546    32    41     9]\n",
      " [  139     1     1     4    50    12    49     0     1]\n",
      " [  759     4     6     8    47    21     8    64     5]\n",
      " [  262     1     3     1    24     7     8     3    37]]\n",
      "Validation F1: 0.35197016549798604, train loss: 0.24182627712461083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(datasets['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "valid_dl = DataLoader(datasets['validation'], batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "losses = train(model, train_dl, valid_dl, optimizer, n_epochs, device)\n",
    "model.load_state_dict(torch.load('best_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4d2f1b383a47e5b83aaf33faa6e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/3453 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35613   132   152   267  1761   215    89    28    66]\n",
      " [  765   434    44    97   182    79    11     0     5]\n",
      " [  541    49   333    13   182    32     3     0     3]\n",
      " [  686    17     3   743   129    63     4    16     0]\n",
      " [  407     4    11    21   362     9    18     1     2]\n",
      " [  756    13    13   140   168   523    23    29     3]\n",
      " [  125     1     2     0    56     8    61     0     4]\n",
      " [  559     5     2    42    38    11     2    42     1]\n",
      " [  153     3     1     2    34     3     0     3    17]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3605739044062232"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataLoader(datasets['test'], batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "evaluate(model, test_dl, beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fda9608593b48ff9a78f3f6e33e3d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/3453 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35459   228   284   319  1439   272   103    83   136]\n",
      " [  774   433    55   101   161    79     4     3     7]\n",
      " [  541    96   324     3   148    40     4     0     0]\n",
      " [  629    14    11   774   156    46     3    23     5]\n",
      " [  368    12    11    23   397     5     8     1    10]\n",
      " [  725    12    16   145   203   503    18    29    17]\n",
      " [  106     1     1     0    77    14    52     0     6]\n",
      " [  512     5     6    48    44    14     4    55    14]\n",
      " [  146     3     2     4    32     1     3     2    23]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3540767428109095"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_dl, beam_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
