
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/opt/homebrew/lib/python3.9/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/TensorCompare.cpp:333.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
Prev: [1]
Transition: tensor([[ 0.0746, -0.0521, -0.0423]], grad_fn=<IndexBackward0>)
Broadcast prev score: tensor([0.5985, 0.5985, 0.5985], grad_fn=<ExpandBackward0>)
Broadcast emission: tensor([0.2616, 0.2801, 0.1663], grad_fn=<SelectBackward0>)
Next score: tensor([0.9347, 0.8265, 0.7224], grad_fn=<AddBackward0>)
Prev: [0]
Transition: tensor([[ 0.0238,  0.0613, -0.0064]], grad_fn=<IndexBackward0>)
Broadcast prev score: tensor([-0.0485, -0.0485, -0.0485], grad_fn=<ExpandBackward0>)
Broadcast emission: tensor([0.2616, 0.2801, 0.1663], grad_fn=<SelectBackward0>)
Next score: tensor([0.2369, 0.2929, 0.1113], grad_fn=<AddBackward0>)
[(([1, 0], tensor(0.9347, grad_fn=<SelectBackward0>)), tensor(0.9347, grad_fn=<SelectBackward0>)), (([1, 1], tensor(0.8265, grad_fn=<SelectBackward0>)), tensor(0.8265, grad_fn=<SelectBackward0>))]
Prev: ([1, 0], tensor(0.9347, grad_fn=<SelectBackward0>))