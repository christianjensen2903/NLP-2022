{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Model import Model\n",
    "from models.GPT2Generator import GPT2Generator\n",
    "from models.Logistic.BOWLogistic import BOWLogistic\n",
    "from models.MLP.BOWMLP import BOWMLP\n",
    "from models.MLP.CBOW_BOWMLP import CBOW_BOWMLP\n",
    "from models.MLP.CBOWMLP import CBOWMLP\n",
    "from models.RandomForest.BOWRandomForest import BOWRandomForest\n",
    "from models.RandomForest.CBOW_BOWRandomForest import CBOW_BOWRandomForest\n",
    "from models.RandomForest.CBOWRandomForest import CBOWRandomForest\n",
    "from models.Logistic.CBOW_BOWLogistic import CBOW_BOWLogistic\n",
    "from models.Logistic.CBOWLogistic import CBOWLogistic\n",
    "from models.XGBoost.BOWXGBoost import BOWXGBoost\n",
    "from models.XGBoost.CBOW_BOWXGBoost import CBOW_BOWXGBoost\n",
    "from models.XGBoost.CBOWXGBoost import CBOWXGBoost\n",
    "\n",
    "from models.SequenceLabeller_BiLSTM_CRF import SequenceLabeller_BiLSTM_CRF\n",
    "from models.SequenceLabeller_BiLSTM_CRF_Beam import SequenceLabeller_BiLSTM_CRF_Beam\n",
    "from models.SequenceLabeller_BERT import SequenceLabeller_BERT\n",
    "\n",
    "\n",
    "from languages.LanguageModel import LanguageModel\n",
    "from DataExploration import DataExploration\n",
    "# from languages.Japanese import Japanese\n",
    "from languages.English import English\n",
    "from languages.Finnish import Finnish\n",
    "from Preprocess import Preprocess\n",
    "from Pipeline import Pipeline\n",
    "from typing import List\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download word_vectors\n",
    "!mkdir word_vectors\n",
    "%cd word_vectors\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fi.300.vec.gz\n",
    "\n",
    "!gzip -d cc.en.300.vec.gz\n",
    "!gzip -d cc.ja.300.vec.gz\n",
    "!gzip -d cc.fi.300.vec.gz\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_reproducibility(seed=42):\n",
    "    # Sets seed manually for both CPU and CUDA\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # For atomic operations there is currently \n",
    "    # no simple way to enforce determinism, as\n",
    "    # the order of parallel operations is not known.\n",
    "    # CUDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # System based\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "enforce_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is used to minimize the clutter in the console\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "# Define the languages to be used\n",
    "languages: List[LanguageModel] = [\n",
    "    English(),\n",
    "    Finnish(),\n",
    "    #Japanese()\n",
    "]\n",
    "\n",
    "# gpt2Generator = GPT2Generator()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_headline(language: str):\n",
    "    print(f'\\n\\n--- Language: {language} ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "\n",
    "for language in languages:\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # Get the preprocessed data and split it into training and validation data\n",
    "    preprocessor = Preprocess(language.tokenize, language.clean)\n",
    "    data = pipeline.get_data(language=language.name, preproccesor=preprocessor)\n",
    "    train_data, validation_data = pipeline.split_data(data)\n",
    "\n",
    "    all_data[language.name] = {\n",
    "        \"train_data\": train_data,\n",
    "        \"validation_data\": validation_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data for each language\n",
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "    data_exploration = DataExploration(all_data[language.name][\"train_data\"])\n",
    "    data_exploration.find_frequent_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Question Classification\n",
    "Binary classfiers that only takes features based on the question, context document and combinations of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    feature_based_classifiers = [\n",
    "        BOWRandomForest(language.name),\n",
    "        BOWMLP(language.name),\n",
    "        BOWLogistic(language.name),\n",
    "        BOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Learning\n",
    "Extension of our binary question classifers to also include features based on continous vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    continous_based_classifiers = [\n",
    "        CBOW_BOWRandomForest(language.name),\n",
    "        CBOW_BOWMLP(language.name),\n",
    "        CBOW_BOWLogistic(language.name),\n",
    "        CBOW_BOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also test how the performance if only the continous representations was to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    continous_based_classifiers = [\n",
    "        CBOWRandomForest(language.name),\n",
    "        CBOWMLP(language.name),\n",
    "        CBOWLogistic(language.name),\n",
    "        CBOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modelling\n",
    "Extension to the classifiers in which word/sentence representations are instead extracted from neural language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    classifier = GPT2CBOWLogistic(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(train_data),\n",
    "        y=classifier.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    pipeline.evaluate(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(validation_data),\n",
    "        y=classifier.extract_y(validation_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to sample from these language models to see what kinds of sentences they generate. Moreover we measure the performance on the TyDi QA validation data with a commonly used language model evaluations metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_beginning = {\n",
    "    'english': ['When', 'What', 'How'],\n",
    "    'finnish': ['Milloin', 'Mikä', 'Missä'],\n",
    "    'japanese': ['日本', '『', 'アメリカ']\n",
    "}\n",
    "\n",
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    model = GPT2Generator(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(train_data),\n",
    "        y=classifier.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    for starting_word in question_beginning[language.name]:\n",
    "        model.generate_text(f'Question: {starting_word}')\n",
    "    model.get_perplexity(model.extract_X(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labelling\n",
    "We implement a sequence labeller, which predicts which parts of a paragraph are likel part of the answer to the corresponding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_train_epochs': 10,\n",
    "    'learning_rate': 2e-5,\n",
    "    'per_device_train_batch_size': 8,\n",
    "    'per_device_eval_batch_size': 8,\n",
    "    'warmup_steps': 200,\n",
    "    'weight_decay': 0.01,\n",
    "    'lstm_dim': 128,\n",
    "    'dropout_prob': 0.1,\n",
    "    'n_workers': 0,\n",
    "    'beam_size': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    sequence_labellers = [\n",
    "        SequenceLabeller_BERT(language.name, config),\n",
    "        SequenceLabeller_BiLSTM_CRF(language.name, config),\n",
    "    ]\n",
    "\n",
    "    for sequence_labeller in sequence_labellers:\n",
    "        print(f'--- Sequence Labeller: {sequence_labeller.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(train_data),\n",
    "            y=sequence_labeller.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(validation_data),\n",
    "            y=sequence_labeller.extract_y(validation_data)\n",
    "        )\n",
    "        sequence_labeller.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an extension to the sequence labeller which uses beam search to select the optimal sequence of labels for the location of the answer in the text. Analyse how the performance of this system differs with beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    sequence_labeller = SequenceLabeller_BiLSTM_CRF_Beam(language.name, config)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(train_data),\n",
    "        y=sequence_labeller.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    num_beams = [1, 2, 3]\n",
    "\n",
    "    for beam in num_beams:\n",
    "        sequence_labeller.beam_size = beam\n",
    "        pipeline.evaluate(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(validation_data),\n",
    "            y=sequence_labeller.extract_y(validation_data)\n",
    "        )\n",
    "    \n",
    "    sequence_labeller.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ab811971494a6cb238a40f596ffb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When was github created?\n",
      "Answer: February 2008\n",
      "Predicted answers: []\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7805c77953de4e11a9bab1961f794854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the first leader of West Germany?\n",
      "Answer: Theodor Heuss\n",
      "Predicted answers: ['Theodor Heuss']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f2dafc54624b5c829fa23d77145f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What martial arts do Marines learn?\n",
      "Answer: Marine Corps Martial Arts Program\n",
      "Predicted answers: ['combine existing and new hand-to-hand and close quarters combat techniques with morale and team-building functions and instruction in the Warrior Ethos', '[', 'which began in 2001 , trains Marines', 'of']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c059d0efae4305a059b7023596a915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the world's largest horse show?\n",
      "Answer: Devon Horse Show\n",
      "Predicted answers: ['Since 1896 , the Devon Horse', 'is']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd475eb3b734cf19caa738f0fbd8114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When did the first episode of Big Brother Australia air?\n",
      "Answer: \n",
      "Predicted answers: []\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba342893daeb4ba2aa7370449631dc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When was Nike founded?\n",
      "Answer: January 25, 1964\n",
      "Predicted answers: []\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ad7baa4734456e987ba27aa8866385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: When did Final Fantasy Type-0 come out?\n",
      "Answer: \n",
      "Predicted answers: []\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485792f78b57402e931b61a9caeefcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the oldest city in Myanmar?\n",
      "Answer: Beikthano\n",
      "Predicted answers: []\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d38f4d4e2d495ea45db0e69bbcfe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the strongest recorded wind?\n",
      "Answer: was during the passage of Tropical Cyclone Olivia on 10 April 1996: an automatic weather station on Barrow Island, Australia, registered a maximum wind gust of 408km/h\n",
      "Predicted answers: []\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a083edecaf724279955568bd255d004f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokenized_question, tags, tokenized_plaintext, __index_level_0__. If tokenized_question, tags, tokenized_plaintext, __index_level_0__ are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was president in 1817?\n",
      "Answer: \n",
      "Predicted answers: []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Qualitative investigation of the predicted answer spans\n",
    "transformers.logging.set_verbosity_error()\n",
    "sequence_labeller = SequenceLabeller_BERT('english', config)\n",
    "sequence_labeller.load()\n",
    "\n",
    "validation_data = all_data['english'][\"validation_data\"]\n",
    "\n",
    "for i in range(10):\n",
    "    i += 10 # plus 10 due to the first 10 examples being mostly withouth answer\n",
    "    row = validation_data.iloc[[i]]\n",
    "    X = sequence_labeller.extract_X(row)\n",
    "\n",
    "    predictions = sequence_labeller.predict(X)[0] # [0] because we only have one example\n",
    "\n",
    "    predicted_answers = ['']\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "\n",
    "        predicted_label = predictions[i]\n",
    "        if predicted_label == 'B' or predicted_label == 'I': # if the label is B or I, we add the token to the current answer\n",
    "            predicted_answers[-1] += row['tokenized_plaintext'].values[0][i] + ' '\n",
    "\n",
    "        elif predicted_label == 'O' and predicted_answers[-1] != '': # if the label is O and the current answer is not empty, we add a new answer\n",
    "            predicted_answers[-1] = predicted_answers[-1][:-1] # remove trailing space\n",
    "            predicted_answers.append('')\n",
    "\n",
    "    if predicted_answers[-1] == '': # remove last empty answer\n",
    "        predicted_answers = predicted_answers[:-1]\n",
    "\n",
    "\n",
    "    print(f'Question: {row[\"question_text\"].values[0]}')\n",
    "    print(f'Answer: {row[\"answer_text\"].values[0]}')\n",
    "    print(f'Predicted answers: {predicted_answers}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by implementing our binary question system with a multilingual encoder instead of the monolingual ones. With this we perform zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutli-lingual binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement our sequence tagger with a multilingual encoding and perform zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero shot classification\n",
    "for language in languages:\n",
    "    print(f'\\n\\n--- Training on {language.name} ---')\n",
    "\n",
    "    sequence_labeller = SequenceLabeller_BERT('multilingual', config)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(train_data),\n",
    "        y=sequence_labeller.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    for language in languages:\n",
    "      print(f'--- Validating on {language.name} ---')\n",
    "      validation_data = all_data[language.name]['validation_data']\n",
    "      pipeline.evaluate(\n",
    "          model=sequence_labeller,\n",
    "          X=sequence_labeller.extract_X(validation_data),\n",
    "          y=sequence_labeller.extract_y(validation_data)\n",
    "      )\n",
    "    \n",
    "    sequence_labeller.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
