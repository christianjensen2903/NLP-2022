
You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
Top candidates: ([1, 1], tensor(0.2798, grad_fn=<SelectBackward0>))
[(([1, 1], tensor(0.2798, grad_fn=<SelectBackward0>)), tensor(0.2798, grad_fn=<SelectBackward0>)), (([1, 2], tensor(0.1574, grad_fn=<SelectBackward0>)), tensor(0.1574, grad_fn=<SelectBackward0>))]
/opt/homebrew/lib/python3.9/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  /Users/distiller/project/pytorch/aten/src/ATen/native/TensorCompare.cpp:333.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)