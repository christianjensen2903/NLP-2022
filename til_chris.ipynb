{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p2tQbYgsDOVW"
      },
      "outputs": [],
      "source": [
        "#%rm saved_models -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOKjTu_hoOpP",
        "outputId": "84aeed28-d3d4-4fcd-d416-289be7270577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "fatal: destination path 'QuestionAnswering' already exists and is not an empty directory.\n",
            "/content/QuestionAnswering\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: fugashi[unidic] in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: libvoikko in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.3)\n",
            "Requirement already satisfied: advertools in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.23.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.90)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.1.91)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.3.5.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (2022.10.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (4.13.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (0.70.13)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->-r requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets->-r requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2022.9.24)\n",
            "Requirement already satisfied: twython>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from advertools->-r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.4 in /usr/local/lib/python3.7/dist-packages (from advertools->-r requirements.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: scrapy>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from advertools->-r requirements.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets->-r requirements.txt (line 1)) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (22.10.0)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (3.4.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (2.0.1)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.0.6)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.6.2)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (2.0.6)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (4.9.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (38.0.1)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (21.1.0)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (22.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.3->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.3->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (2.21)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.7/dist-packages (from itemloaders>=1.0.1->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=18.1.0->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (22.10.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (22.10.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (15.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.7/dist-packages (from Twisted>=18.9.0->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (21.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython>=3.8.0->advertools->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython>=3.8.0->advertools->-r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 5)) (2022.6.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost->-r requirements.txt (line 6)) (1.7.3)\n",
            "Requirement already satisfied: unidic in /usr/local/lib/python3.7/dist-packages (from fugashi[unidic]->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy>=2.5.0->advertools->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from unidic->fugashi[unidic]->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from unidic->fugashi[unidic]->-r requirements.txt (line 2)) (1.3.5)\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), done.\n",
            "From https://github.com/christianjensen2903/QuestionAnswering\n",
            "   7c667ad..4fa3dbf  before_change_to_model -> origin/before_change_to_model\n",
            "Updating 7c667ad..4fa3dbf\n",
            "Fast-forward\n",
            " models/GPT2Generator.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"%cd /content\n",
        "!git clone -b before_change_to_model https://github.com/christianjensen2903/QuestionAnswering.git\n",
        "%cd QuestionAnswering\n",
        "!pip install -r requirements.txt\n",
        "!git pull\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0ifXPHavoX1Z"
      },
      "outputs": [],
      "source": [
        "from models.Logistic.MultiGPT2Logistic import MultiGPT2Logistic\n",
        "from models.Logistic.GPT2Logistic import GPT2Logistic\n",
        "from languages.LanguageModel import LanguageModel\n",
        "from DataExploration import DataExploration\n",
        "from languages.Japanese import Japanese\n",
        "from languages.English import English\n",
        "from languages.Finnish import Finnish\n",
        "from Preprocess import Preprocess\n",
        "from models.Model import Model\n",
        "from Pipeline import Pipeline\n",
        "from typing import List\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets\n",
        "import torch\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AIaL1972ocpw"
      },
      "outputs": [],
      "source": [
        "def enforce_reproducibility(seed=42):\n",
        "    # Sets seed manually for both CPU and CUDA\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # For atomic operations there is currently \n",
        "    # no simple way to enforce determinism, as\n",
        "    # the order of parallel operations is not known.\n",
        "    # CUDNN\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # System based\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9U6mETd3ofgX"
      },
      "outputs": [],
      "source": [
        "# Is used to minimize the clutter in the console\n",
        "datasets.logging.set_verbosity_error()\n",
        "\n",
        "# Define the languages to be used\n",
        "languages: List[LanguageModel] = [\n",
        "    Japanese(),\n",
        "    Finnish(),\n",
        "    English(),\n",
        "]\n",
        "\n",
        "# gpt2Generator = GPT2Generator()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cxl3D5VohrX",
        "outputId": "ecc661e2-11e6-422d-867c-1ff844af9b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading data...\n",
            "\n",
            "Loading data...\n",
            "\n",
            "Loading data...\n"
          ]
        }
      ],
      "source": [
        "all_data = {}\n",
        "\n",
        "for language in languages:\n",
        "    pipeline = Pipeline()\n",
        "\n",
        "    # Get the preprocessed data and split it into training and validation data\n",
        "    preprocessor = Preprocess(language.tokenize, language.clean)\n",
        "    data = pipeline.get_data(language=language.name, preproccesor=preprocessor)\n",
        "    train_data, validation_data = pipeline.split_data(data)\n",
        "\n",
        "    all_data[language.name] = {\n",
        "        \"train_data\": train_data,\n",
        "        \"validation_data\": validation_data\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9Pjfb3IAo7BD"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    GPT2Logistic()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ahgSaEdkqPnf"
      },
      "outputs": [],
      "source": [
        "question_beginning = {\n",
        "    'english': ['Question: When', 'Question: What', 'Question: How'],\n",
        "    'finnish': ['Question: Milloin', 'Question: Mikä', 'Question: Missä'],\n",
        "    'japanese': ['Question: 日本', 'Question: 『', 'Question: アメリカ']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ivYPDIi7qkGx"
      },
      "outputs": [],
      "source": [
        "def test_gpt2(model, validation_data, language_name):\n",
        "    for starting_word in question_beginning[language_name]:\n",
        "        model.generate_text(starting_word)\n",
        "    X_validation = model.extract_X(validation_data)\n",
        "    y_validation = validation_data['is_answerable']\n",
        "    print(model.get_perplexity(X_validation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bTcjYqP3vFS5"
      },
      "outputs": [],
      "source": [
        "#all_data[\"japanese\"][\"train_data\"].head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2Qm8GgOS0Zw_"
      },
      "outputs": [],
      "source": [
        "transformers.logging.set_verbosity_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4a3c83078e944cdb9fa02c74a1bfe5c3",
            "ab960295f82848e495f9e2a62af5b7d8",
            "35695396c30b46a89585c5f8bc42bfeb",
            "f82cf026794b4bf88714025ddbd36ff7",
            "eeb033f9762e4d189e7760281b220f9f",
            "9e8ffb5ae36b4681857f3d18ff330faa",
            "04d48b93a5bd4a86a78c6a15731b83bb",
            "c1362716a50a46ce89c6883736a58f69",
            "2b8b1bfa99af48bcbafdcfa94afc25ba",
            "32f053f13f3442e0809495c5e52835ff",
            "82c2b581e43d4b7eb37ee3bd384fab5c"
          ]
        },
        "id": "9qsSHZMHpE0W",
        "outputId": "957b790a-c909-4b50-898a-d8c1bf4e8992"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt2-small/snapshots/d35a68cf1fea74b71708ce898b351471b5c698ce/spiece.model\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt2-small/snapshots/d35a68cf1fea74b71708ce898b351471b5c698ce/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt2-small/snapshots/d35a68cf1fea74b71708ce898b351471b5c698ce/tokenizer_config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ---- Language!: japanese\n",
            "\n",
            " - Model: GPT2Logistic\n",
            "Extracting features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt2-small/snapshots/d35a68cf1fea74b71708ce898b351471b5c698ce/config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"rinna/japanese-gpt2-small\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": 3072,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"output_hidden_states\": true,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt2-small/snapshots/d35a68cf1fea74b71708ce898b351471b5c698ce/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at rinna/japanese-gpt2-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a3c83078e944cdb9fa02c74a1bfe5c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7851 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 7851\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1473\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='1473' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   3/1473 00:10 < 4:27:32, 0.09 it/s, Epoch 0.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for language in languages:\n",
        "  print(f'\\n ---- Language!: {language.name}')\n",
        "  train_data = all_data[language.name][\"train_data\"]\n",
        "  validation_data = all_data[language.name][\"validation_data\"]\n",
        "  for model in models:\n",
        "          model_name = model.__class__.__name__\n",
        "          model.set_language(language.name)\n",
        "          print(f'\\n - Model: {model_name}')\n",
        "\n",
        "          try:\n",
        "              model.load()\n",
        "          except:\n",
        "              print('Extracting features...')\n",
        "              X_train = model.extract_X(train_data)\n",
        "              y_train = train_data['is_answerable']\n",
        "              model = pipeline.train(\n",
        "                  model,\n",
        "                  X_train,\n",
        "                  y_train\n",
        "              )\n",
        "              model.save()\n",
        "          \n",
        "          X_validation = model.extract_X(validation_data)\n",
        "          y_validation = validation_data['is_answerable']\n",
        "          pipeline.evaluate(\n",
        "              model,\n",
        "              X_validation,\n",
        "              y_validation\n",
        "          )\n",
        "          test_gpt2(model.GPT2Generator, validation_data, language.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThQBuoS__n57"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czIGZeqM7xUZ"
      },
      "outputs": [],
      "source": [
        "validation_data = all_data[\"japanese\"][\"validation_data\"].head(20)\n",
        "validation_data[\"document_plaintext\"].str.len()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cdTZhpZ8owq"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\n",
        "    \"rinna/japanese-gpt2-small\",\n",
        "    model_max_length=1024,\n",
        "    truncation=True\n",
        "  )\n",
        "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"rinna/japanese-gpt2-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l2zGDby9ddF"
      },
      "outputs": [],
      "source": [
        "#model_max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QD5UaAk8qvp"
      },
      "outputs": [],
      "source": [
        "data_point = all_data[\"japanese\"][\"validation_data\"].iloc[11]\n",
        "print(len(data_point[\"document_plaintext\"]))\n",
        "str_input = 'Question: ' + \\\n",
        "                data_point['question_text'] + '\\nContext: ' + \\\n",
        "                data_point['document_plaintext']\n",
        "str_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZiFZe6GAoGf"
      },
      "outputs": [],
      "source": [
        "len(tokenizer.encode(str_input, truncation=True, padding=True, return_tensors='pt')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlJ_O-Bm879q"
      },
      "outputs": [],
      "source": [
        "\"\"\"model(tokenizer.encode(str_input, truncation=True, return_tensors='pt')[0])\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "b9c69bc24335dc0e55392644c8f34f14710bb68159a638262db0555ff8c8aa69"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04d48b93a5bd4a86a78c6a15731b83bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b8b1bfa99af48bcbafdcfa94afc25ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32f053f13f3442e0809495c5e52835ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35695396c30b46a89585c5f8bc42bfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1362716a50a46ce89c6883736a58f69",
            "max": 7851,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b8b1bfa99af48bcbafdcfa94afc25ba",
            "value": 7851
          }
        },
        "4a3c83078e944cdb9fa02c74a1bfe5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab960295f82848e495f9e2a62af5b7d8",
              "IPY_MODEL_35695396c30b46a89585c5f8bc42bfeb",
              "IPY_MODEL_f82cf026794b4bf88714025ddbd36ff7"
            ],
            "layout": "IPY_MODEL_eeb033f9762e4d189e7760281b220f9f"
          }
        },
        "82c2b581e43d4b7eb37ee3bd384fab5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8ffb5ae36b4681857f3d18ff330faa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab960295f82848e495f9e2a62af5b7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8ffb5ae36b4681857f3d18ff330faa",
            "placeholder": "​",
            "style": "IPY_MODEL_04d48b93a5bd4a86a78c6a15731b83bb",
            "value": "100%"
          }
        },
        "c1362716a50a46ce89c6883736a58f69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb033f9762e4d189e7760281b220f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82cf026794b4bf88714025ddbd36ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f053f13f3442e0809495c5e52835ff",
            "placeholder": "​",
            "style": "IPY_MODEL_82c2b581e43d4b7eb37ee3bd384fab5c",
            "value": " 7851/7851 [00:10&lt;00:00, 845.16ex/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
