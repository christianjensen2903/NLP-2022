{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Model import Model\n",
    "from models.GPT2CBOWLogistic import GPT2CBOWLogistic\n",
    "from models.GPT2Generator import GPT2Generator\n",
    "from models.Logistic.BOWLogistic import BOWLogistic\n",
    "from models.MLP.BOWMLP import BOWMLP\n",
    "from models.MLP.CBOW_BOWMLP import CBOW_BOWMLP\n",
    "from models.MLP.CBOWMLP import CBOWMLP\n",
    "from models.RandomForest.BOWRandomForest import BOWRandomForest\n",
    "from models.RandomForest.CBOW_BOWRandomForest import CBOW_BOWRandomForest\n",
    "from models.RandomForest.CBOWRandomForest import CBOWRandomForest\n",
    "from models.Logistic.CBOW_BOWLogistic import CBOW_BOWLogistic\n",
    "from models.Logistic.CBOWLogistic import CBOWLogistic\n",
    "from models.XGBoost.BOWXGBoost import BOWXGBoost\n",
    "from models.XGBoost.CBOW_BOWXGBoost import CBOW_BOWXGBoost\n",
    "from models.XGBoost.CBOWXGBoost import CBOWXGBoost\n",
    "\n",
    "from models.SequenceLabeller_BiLSTM_CRF import SequenceLabeller_BiLSTM_CRF\n",
    "from models.SequenceLabeller_BiLSTM_CRF_Beam import SequenceLabeller_BiLSTM_CRF_Beam\n",
    "from models.SequenceLabeller_BERT import SequenceLabeller_BERT\n",
    "\n",
    "\n",
    "from languages.LanguageModel import LanguageModel\n",
    "from DataExploration import DataExploration\n",
    "# from languages.Japanese import Japanese\n",
    "from languages.English import English\n",
    "from languages.Finnish import Finnish\n",
    "from Preprocess import Preprocess\n",
    "from Pipeline import Pipeline\n",
    "from typing import List\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is used to minimize the clutter in the console\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "# Define the languages to be used\n",
    "languages: List[LanguageModel] = [\n",
    "    English(),\n",
    "    Finnish(),\n",
    "    # Japanese()\n",
    "]\n",
    "\n",
    "# gpt2Generator = GPT2Generator()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_headline(language: str):\n",
    "    print(f'\\n\\n--- Language: {language} ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "\n",
    "for language in languages:\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # Get the preprocessed data and split it into training and validation data\n",
    "    preprocessor = Preprocess(language.tokenize, language.clean)\n",
    "    data = pipeline.get_data(language=language.name, preproccesor=preprocessor)\n",
    "    train_data, validation_data = pipeline.split_data(data)\n",
    "\n",
    "    all_data[language.name] = {\n",
    "        \"train_data\": train_data,\n",
    "        \"validation_data\": validation_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Language: english ---\n",
      "\n",
      "Most frequent first words:\n",
      "[('When', 1994), ('What', 1967), ('How', 1188), ('Who', 945), ('Where', 419)]\n",
      "Most frequent last words:\n",
      "[('?', 6693), ('\\\\', 2), ('BCE', 2), (\"''\", 2), ('metabolite', 1)]\n",
      "\n",
      "\n",
      "\n",
      "--- Language: finnish ---\n",
      "\n",
      "Most frequent first words:\n",
      "[('Milloin', 3210), ('Mikä', 2048), ('Missä', 1508), ('Kuka', 1435), ('Mitä', 928)]\n",
      "Most frequent last words:\n",
      "[('?', 12292), ('tohtoriksi+', 2), ('syntynyt', 2), ('pinta-ala', 2), ('=', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explore the data for each language\n",
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "    data_exploration = DataExploration(all_data[language.name][\"train_data\"])\n",
    "    data_exploration.find_frequent_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Question Classification\n",
    "Binary classfiers that only takes features based on the question, context document and combinations of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    feature_based_classifiers = [\n",
    "        BOWRandomForest(language.name),\n",
    "        BOWMLP(language.name),\n",
    "        BOWLogistic(language.name),\n",
    "        BOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Learning\n",
    "Extension of our binary question classifers to also include features based on continous vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    continous_based_classifiers = [\n",
    "        CBOW_BOWRandomForest(language.name),\n",
    "        CBOW_BOWMLP(language.name),\n",
    "        CBOW_BOWLogistic(language.name),\n",
    "        CBOW_BOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also test how the performance if only the continous representations was to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    continous_based_classifiers = [\n",
    "        CBOWRandomForest(language.name),\n",
    "        CBOWMLP(language.name),\n",
    "        CBOWLogistic(language.name),\n",
    "        CBOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modelling\n",
    "Extension to the classifiers in which word/sentence representations are instead extracted from neural language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    classifier = GPT2CBOWLogistic(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(train_data),\n",
    "        y=classifier.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    pipeline.evaluate(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(validation_data),\n",
    "        y=classifier.extract_y(validation_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to sample from these language models to see what kinds of sentences they generate. Moreover we measure the performance on the TyDi QA validation data with a commonly used language model evaluations metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_beginning = {\n",
    "    'english': ['When', 'What', 'How'],\n",
    "    'finnish': ['Milloin', 'Mikä', 'Missä'],\n",
    "    'japanese': ['日本', '『', 'アメリカ']\n",
    "}\n",
    "\n",
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    model = GPT2Generator(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(train_data),\n",
    "        y=classifier.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    for starting_word in question_beginning[language.name]:\n",
    "        model.generate_text(f'Question: {starting_word}')\n",
    "    model.get_perplexity(model.extract_X(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labelling\n",
    "We implement a sequence labeller, which predicts which parts of a paragraph are likel part of the answer to the corresponding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    sequence_labellers = [\n",
    "        SequenceLabeller_BiLSTM_CRF(language.name),\n",
    "        SequenceLabeller_BERT(language.name),\n",
    "    ]\n",
    "\n",
    "    for sequence_labeller in sequence_labellers:\n",
    "        print(f'--- Sequence Labeller: {sequence_labeller.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(train_data),\n",
    "            y=sequence_labeller.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(validation_data),\n",
    "            y=sequence_labeller.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an extension to the sequence labeller which uses beam search to select the optimal sequence of labels for the location of the answer in the text. Analyse how the performance of this system differs with beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    sequence_labeller = SequenceLabeller_BiLSTM_CRF_Beam(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(train_data),\n",
    "        y=sequence_labeller.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    num_beams = [1, 2, 3]\n",
    "\n",
    "    for beam in num_beams:\n",
    "        sequence_labeller.beam_size = beam\n",
    "        pipeline.evaluate(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(validation_data),\n",
    "            y=sequence_labeller.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative investigation of the predicted answer spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by implementing our binary question system with a multilingual encoder instead of the monolingual ones. With this we perform zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutli-lingual binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement our sequence tagger with a multilingual encoding and perform zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Training on english ---\n",
      "--- Validation on ['finnish'] ---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_1870/2660802411.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'--- Validation on {val_languages} ---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msequence_labeller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceLabeller_BERT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilingual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "# Zero shot classification\n",
    "for language in languages:\n",
    "    print(f'\\n\\n--- Training on {language.name} ---')\n",
    "\n",
    "    val_languages = [l.name for l in languages if l.name != language.name]\n",
    "    print(f'--- Validation on {val_languages} ---')\n",
    "\n",
    "    sequence_labeller = SequenceLabeller_BERT('multilingual', {})\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    val_df = [all_data[val_name]['validation_data'] for val_name in val_languages]\n",
    "\n",
    "    validation_data = pd.concat(val_df, ignore_index=True, axis=0)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(train_data),\n",
    "        y=sequence_labeller.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    pipeline.evaluate(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(validation_data),\n",
    "        y=sequence_labeller.extract_y(validation_data)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
