{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/homebrew/lib/python3.9/site-packages (from fasttext) (65.4.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.9/site-packages (from fasttext) (1.22.4)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[151 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/FastText.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/util.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating var\n",
      "  \u001b[31m   \u001b[0m creating var/folders\n",
      "  \u001b[31m   \u001b[0m creating var/folders/s3\n",
      "  \u001b[31m   \u001b[0m creating var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn\n",
      "  \u001b[31m   \u001b[0m creating var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpp7byioas.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpp7byioas.o -stdlib=libc++\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:08.909 xcodebuild[9093:2402976] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:08.935 xcodebuild[9093:2402976] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x12ba710d0>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x14ae0c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001024493d0\n",
      "  \u001b[31m   \u001b[0m   1  0x0000000102448aac\n",
      "  \u001b[31m   \u001b[0m   2  0x0000000102448c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x00000001022f726c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001022bd0d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001022bb4e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x000000010248d54c\n",
      "  \u001b[31m   \u001b[0m   9  0x0000000102469470\n",
      "  \u001b[31m   \u001b[0m  10  0x00000001022bb380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001022bb5a0\n",
      "  \u001b[31m   \u001b[0m  12  0x000000010337f2ec\n",
      "  \u001b[31m   \u001b[0m  13  0x000000010337eae0\n",
      "  \u001b[31m   \u001b[0m  14  0x000000010337e1e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000100d1c324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000100aade0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9095 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp2w4_qwe5.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp2w4_qwe5.o -stdlib=libc++ -mmacosx-version-min=10.7\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:09.699 xcodebuild[9099:2403021] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:09.721 xcodebuild[9099:2403021] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x11eb951e0>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x12560c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001061b13d0\n",
      "  \u001b[31m   \u001b[0m   1  0x00000001061b0aac\n",
      "  \u001b[31m   \u001b[0m   2  0x00000001061b0c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x000000010605f26c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001060250d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001060234e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x00000001061f554c\n",
      "  \u001b[31m   \u001b[0m   9  0x00000001061d1470\n",
      "  \u001b[31m   \u001b[0m  10  0x0000000106023380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001060235a0\n",
      "  \u001b[31m   \u001b[0m  12  0x00000001070e72ec\n",
      "  \u001b[31m   \u001b[0m  13  0x00000001070e6ae0\n",
      "  \u001b[31m   \u001b[0m  14  0x00000001070e61e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000104a84324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000104815e0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9101 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 168, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/wheel/bdist_wheel.py\", line 299, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('build')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 131, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(\n",
      "  \u001b[31m   \u001b[0m RuntimeError: libc++ is needed! Failed to compile with -stdlib=libc++ -mmacosx-version-min=10.7 and -stdlib=libc++.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for fasttext\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for fasttext ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for fasttext\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[150 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /opt/homebrew/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/FastText.py -> build/lib.macosx-12-arm64-cpython-39/fasttext\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/util.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/util/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/util\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_script.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/__init__.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m copying python/fasttext_module/fasttext/tests/test_configurations.py -> build/lib.macosx-12-arm64-cpython-39/fasttext/tests\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp5n4fjd87.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmp5n4fjd87.o -stdlib=libc++\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:11.927 xcodebuild[9105:2403147] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:11.947 xcodebuild[9105:2403147] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x10c42b740>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x12e60c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001028953d0\n",
      "  \u001b[31m   \u001b[0m   1  0x0000000102894aac\n",
      "  \u001b[31m   \u001b[0m   2  0x0000000102894c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x000000010274326c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001027090d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001027074e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x00000001028d954c\n",
      "  \u001b[31m   \u001b[0m   9  0x00000001028b5470\n",
      "  \u001b[31m   \u001b[0m  10  0x0000000102707380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001027075a0\n",
      "  \u001b[31m   \u001b[0m  12  0x00000001037cb2ec\n",
      "  \u001b[31m   \u001b[0m  13  0x00000001037caae0\n",
      "  \u001b[31m   \u001b[0m  14  0x00000001037ca1e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000101168324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000100ef9e0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9107 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c /var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpm6wmyxcx.cpp -o var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/tmpm6wmyxcx.o -stdlib=libc++ -mmacosx-version-min=10.7\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:12.642 xcodebuild[9109:2403170] [MT] DVTPlugInLoading: Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin), error = Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}, dyldError = dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0000): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\n",
      "  \u001b[31m   \u001b[0m 2022-10-20 23:10:12.662 xcodebuild[9109:2403170] [MT] DVTAssertions: ASSERTION FAILURE in /System/Volumes/Data/SWE/Apps/DT/BuildRoots/BuildRoot2/ActiveBuildRoot/Library/Caches/com.apple.xbs/Sources/DVTFrameworks/DVTFrameworks-21304/DVTFoundation/PlugInArchitecture/DataModel/DVTPlugIn.m:374\n",
      "  \u001b[31m   \u001b[0m Details:  Failed to load code for plug-in com.apple.dt.IDESimulatorAvailability (/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin)\n",
      "  \u001b[31m   \u001b[0m Please ensure Xcode packages are up-to-date — try running 'xcodebuild -runFirstLaunch'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m NSBundle error: Error Domain=NSCocoaErrorDomain Code=3588 \"dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator'\" UserInfo={NSLocalizedFailureReason=The bundle couldn’t be loaded., NSLocalizedRecoverySuggestion=Try reinstalling the bundle., NSFilePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, NSDebugDescription=dlopen(/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability, 0x0109): Symbol not found: (_OBJC_CLASS_$_SimDiskImage)\n",
      "  \u001b[31m   \u001b[0m   Referenced from: '/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin/Contents/MacOS/IDESimulatorAvailability'\n",
      "  \u001b[31m   \u001b[0m   Expected in: '/Library/Developer/PrivateFrameworks/CoreSimulator.framework/Versions/A/CoreSimulator', NSBundlePath=/Applications/Xcode.app/Contents/PlugIns/IDESimulatorAvailability.ideplugin, NSLocalizedDescription=The bundle “IDESimulatorAvailability” couldn’t be loaded.}\n",
      "  \u001b[31m   \u001b[0m Object:   <DVTPlugIn: 0x13b91c5e0>\n",
      "  \u001b[31m   \u001b[0m Method:   -loadAssertingOnError:error:\n",
      "  \u001b[31m   \u001b[0m Thread:   <_NSMainThread: 0x15b60c6b0>{number = 1, name = main}\n",
      "  \u001b[31m   \u001b[0m Hints:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Backtrace:\n",
      "  \u001b[31m   \u001b[0m   0  0x00000001043313d0\n",
      "  \u001b[31m   \u001b[0m   1  0x0000000104330aac\n",
      "  \u001b[31m   \u001b[0m   2  0x0000000104330c2c\n",
      "  \u001b[31m   \u001b[0m   3  0x00000001041df26c\n",
      "  \u001b[31m   \u001b[0m   4  0x00000001041a50d8\n",
      "  \u001b[31m   \u001b[0m   5  0x00000001041a34e8\n",
      "  \u001b[31m   \u001b[0m   6  0x00000001a55ec1b4\n",
      "  \u001b[31m   \u001b[0m   7  0x00000001a55fb414\n",
      "  \u001b[31m   \u001b[0m   8  0x000000010437554c\n",
      "  \u001b[31m   \u001b[0m   9  0x0000000104351470\n",
      "  \u001b[31m   \u001b[0m  10  0x00000001041a3380\n",
      "  \u001b[31m   \u001b[0m  11  0x00000001041a35a0\n",
      "  \u001b[31m   \u001b[0m  12  0x00000001051b32ec\n",
      "  \u001b[31m   \u001b[0m  13  0x00000001051b2ae0\n",
      "  \u001b[31m   \u001b[0m  14  0x00000001051b21e8\n",
      "  \u001b[31m   \u001b[0m  15  0x0000000102a80324\n",
      "  \u001b[31m   \u001b[0m  16  0x0000000102a31e0c\n",
      "  \u001b[31m   \u001b[0m sh: line 1:  9111 Abort trap: 6           /Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null\n",
      "  \u001b[31m   \u001b[0m clang: error: sh -c '/Applications/Xcode.app/Contents/Developer/usr/bin/xcodebuild -sdk /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk -find clang 2> /dev/null' failed with exit code 34304: (null) (errno=Invalid argument)\n",
      "  \u001b[31m   \u001b[0m xcode-select: Failed to locate 'clang', requesting installation of command line developer tools.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 168, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/command/install.py\", line 68, in run\n",
      "  \u001b[31m   \u001b[0m     return orig.install.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/install.py\", line 698, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('build')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/cmd.py\", line 319, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/homebrew/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/pip-install-8dlxh1xg/fasttext_36ec3dce5b3b4775a7f3a70679e44a16/setup.py\", line 131, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(\n",
      "  \u001b[31m   \u001b[0m RuntimeError: libc++ is needed! Failed to compile with -stdlib=libc++ -mmacosx-version-min=10.7 and -stdlib=libc++.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m fasttext\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytorch-crf in /opt/homebrew/lib/python3.9/site-packages (0.7.2)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: datasets in /opt/homebrew/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.9.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/homebrew/lib/python3.9/site-packages (from datasets) (2022.8.2)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.9/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.9/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.9/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/lib/python3.9/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/homebrew/lib/python3.9/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/homebrew/lib/python3.9/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sklearn in /opt/homebrew/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.9/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "!pip install pytorch-crf\n",
    "!pip install datasets\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import torch\n",
    "import random\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchcrf import CRF\n",
    "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
    "from typing import List, Tuple, AnyStr\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from datasets import load_dataset, load_metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocess import Preprocess\n",
    "from Pipeline import Pipeline\n",
    "from languages.English import English\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "english = English()\n",
    "\n",
    "preproccesor = Preprocess(english.tokenize, english.clean)\n",
    "data = Pipeline().get_data(language=english.name, preproccesor=preproccesor)\n",
    "train_data, validation_data = Pipeline().split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tag_token(token, index, answer_start, answer_end):\n",
    "        \"\"\"Tag a token with the IOB format\"\"\"\n",
    "        if index == answer_start:\n",
    "            return 2 # B\n",
    "        elif answer_start < index <= answer_end:\n",
    "            return 1 # I\n",
    "        else:\n",
    "            return 0 # O\n",
    "\n",
    "def _tag_sentence(sentence, answer_start, answer_end):\n",
    "    \"\"\"Tag a sentence with the IOB format\"\"\"\n",
    "    return [\n",
    "        _tag_token(token, index, answer_start, answer_end)\n",
    "        for index, token in enumerate(sentence)\n",
    "    ]\n",
    "\n",
    "def _convert_to_iob(dataset):\n",
    "    \"\"\"Tag the dataset with the IOB format\"\"\"\n",
    "    dataset['tags'] = dataset.apply(lambda row: _tag_sentence(row['text'], row['answer_start'], row['answer_end']), axis=1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def extract_X(dataset, language: str = \"\"):\n",
    "    \"\"\"Extract features from the dataset\"\"\"\n",
    "    dataset['text'] = dataset.apply(lambda row: np.concatenate((['<START>'], row['tokenized_question'], ['<SEP>'], row['tokenized_plaintext'], ['<STOP>'])), axis=1)\n",
    "    dataset['answer_start'] = dataset.apply(lambda row: len(row['tokenized_question'])+2+row['answer_start'], axis=1)\n",
    "    dataset['answer_end'] = dataset.apply(lambda row: len(row['tokenized_question'])+2+row['answer_end'], axis=1)\n",
    "    dataset = _convert_to_iob(dataset)\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(dataset[['text', 'tags']])\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def extract_y(dataset, language: str = \"\"):\n",
    "    \"\"\"Extract the labels from the dataset\"\"\"\n",
    "    y = dataset.apply(lambda row: np.concatenate([['O']*(2+len(row['tokenized_question'])), row['plaintext_tags'], [2]]), axis=1).to_numpy() # O for every token which is not the context and the plus 2 is for the CLS and SEP tags\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = extract_X(train_data, 'english')\n",
    "X_val = extract_X(validation_data, 'english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce down to our vocabulary and word embeddings\n",
    "def load_vectors(fname, vocabulary):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    tag_names = ['B', 'I', 'O']\n",
    "    final_vocab = tag_names + ['[PAD]', '[UNK]', '[BOS]', '[EOS]']\n",
    "    final_vectors = [np.random.normal(size=(300,)) for _ in range(len(final_vocab))]\n",
    "    for j,line in enumerate(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        if tokens[0] in vocabulary or len(final_vocab) < 30000:\n",
    "            final_vocab.append(tokens[0])\n",
    "            final_vectors.append(np.array(list(map(float, tokens[1:]))))\n",
    "    return final_vocab, np.vstack(final_vectors)\n",
    "\n",
    "class FasttextTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocab = {}\n",
    "        for j,l in enumerate(vocabulary):\n",
    "            self.vocab[l.strip()] = j\n",
    "\n",
    "    def encode(self, text):\n",
    "        # Text is assumed to be tokenized\n",
    "        return [self.vocab[t] if t in self.vocab else self.vocab['[UNK]'] for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of vocabulary:  64383\n"
     ]
    }
   ],
   "source": [
    "vocabulary = (set([t for s in X_train for t in s['text']]) | set([t for s in X_val for t in s['text']]))\n",
    "vocabulary, pretrained_embeddings = load_vectors('wiki-news-300d-1M.vec', vocabulary)\n",
    "print('size of vocabulary: ', len(vocabulary))\n",
    "tokenizer = FasttextTokenizer(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    input_ids = [tokenizer.encode(i['text']) for i in input_data]\n",
    "    seq_lens = [len(i) for i in input_ids]\n",
    "    labels = [i['tags'] for i in input_data]\n",
    "\n",
    "    max_length = max([len(i) for i in input_ids])\n",
    "\n",
    "    input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\n",
    "    labels = [(i + [0] * (max_length - len(i))) for i in labels] # 0 is the id of the O tag\n",
    "\n",
    "    assert (all(len(i) == max_length for i in input_ids))\n",
    "    assert (all(len(i) == max_length for i in labels))\n",
    "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    4,  2208,   643,     8,   737,  1122,  2052,    22,    27,  2482,\n",
       "             10,     8, 39256,    44,     4,  1122,  2052,    20,    14,  5727,\n",
       "            737,    22,     8,   290,  4628,  9573,  4943,    27,  2482,    10,\n",
       "              8, 39256,     9,  1122,    29,  1622,    12,     8,   239,    22,\n",
       "            405,   236,     7,  3082,     7,    10,    50,   114,  8297,    32,\n",
       "           7683, 11575,   514,   154,     9,   559,   127,   505, 11199,  1122,\n",
       "             29,    14,     4,   823,  2039,     4,     7,    74,    66,    14,\n",
       "           8322,    24, 17402,  9608,    19, 23205,  1456,  2157,    17,     7,\n",
       "            988,    91,    55, 31702,     9,    27,  1391,  2455,  1764,     7,\n",
       "             54,     8,   112,    43,  1868,   915,   154,     9,   455,    14,\n",
       "            151,    22,     8,   414,     7,  4321,   902,     8,   737,    14,\n",
       "           1590, 30981,     7,  5621,    10,   256,     9,   138,   416,    49,\n",
       "          20403, 10219,  2886, 23058,  2052,    19, 19979, 60821,    17,     9,\n",
       "            455,    14,  1578,  1591,    12,   550,  7556,    19, 15653, 64180,\n",
       "             17,     4,   902,  1917,    12,    49,  1749, 11442,  7556,    19,\n",
       "           6715, 32827,    17,     4,  1472,  1111,  1122,    31,   959,    25,\n",
       "             14,   864, 10957,     7,    25,   229,    25,    49,  1391,    10,\n",
       "           9946,  1591,    12,    10,   246,  5042,    33, 10677, 59431,    19,\n",
       "          21985, 48863,    17,     9,  1122,    31,  4595,    11,  8946, 31412,\n",
       "             24,     4,    49, 32981, 13179, 14363,  2366,    19, 57304, 18787,\n",
       "             17,     7,    10, 24978, 40894,    19, 12427, 59178,    17,     7,\n",
       "              8,  1306,    11,    51,    11,    49,     4,     9,  3395,     8,\n",
       "            155,     7,  1122,  1079,    12,   802,  4315,   892,    13,   638,\n",
       "          20871,    25,    14,   864, 10957,     9,     4]]),\n",
       " tensor([237]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dl = DataLoader(X_val, batch_size=1, shuffle=False, collate_fn=collate_batch_bilstm, num_workers=0)\n",
    "next(iter(dev_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['<START>', 'Who', 'played', 'the', 'character', 'Paul', 'Williams', 'on', 'The', 'Young', 'and', 'the', 'Restless', '?', '<SEP>', 'Paul', 'Williams', 'is', 'a', 'fictional', 'character', 'on', 'the', 'American', 'CBS', 'soap', 'opera', 'The', 'Young', 'and', 'the', 'Restless', '.', 'Paul', 'was', 'introduced', 'to', 'the', 'show', 'on', 'May', '23', ',', '1978', ',', 'and', 'has', 'been', 'portrayed', 'by', 'Doug', 'Davidson', 'ever', 'since', '.', '[', '1', ']', 'Initially', 'Paul', 'was', 'a', '``', 'bad', 'boy', \"''\", ',', 'who', 'had', 'a', 'romance', 'with', 'Nikki', 'Newman', '(', 'Melody', 'Thomas', 'Scott', ')', ',', 'giving', 'her', 'an', 'STD', '.', 'The', 'relationship', 'ultimately', 'ended', ',', 'but', 'the', 'two', 'have', 'remained', 'friends', 'since', '.', 'After', 'a', 'year', 'on', 'the', 'series', ',', 'Bell', 'gave', 'the', 'character', 'a', 'proper', 'backstory', ',', 'surname', 'and', 'family', '.', 'This', 'included', 'his', 'notoriously', 'unstable', 'sister', 'Patty', 'Williams', '(', 'Stacey', 'Haiduk', ')', '.', 'After', 'a', 'failed', 'marriage', 'to', 'April', 'Stevens', '(', 'Cynthia', 'Eilbacher', ')', '—who', 'gave', 'birth', 'to', 'his', 'daughter', 'Heather', 'Stevens', '(', 'Jennifer', 'Landon', ')', '—focus', 'turned', 'towards', 'Paul', \"'s\", 'career', 'as', 'a', 'private', 'investigator', ',', 'as', 'well', 'as', 'his', 'relationship', 'and', 'eventual', 'marriage', 'to', 'and', 'later', 'divorce', 'from', 'Lauren', 'Fenmore', '(', 'Tracey', 'Bregman', ')', '.', 'Paul', \"'s\", 'string', 'of', 'unsuccessful', 'romances', 'with', 'women—including', 'his', 'ill-fated', 'bride', 'Cindy', 'Lake', '(', 'DeAnna', 'Robbins', ')', ',', 'and', 'Cassandra', 'Rawlins', '(', 'Nina', 'Arvesen', ')', ',', 'the', 'wife', 'of', 'one', 'of', 'his', 'clients—continued', '.', 'Over', 'the', 'years', ',', 'Paul', 'continued', 'to', 'become', 'heavily', 'involved', 'in', 'various', 'storylines', 'as', 'a', 'private', 'investigator', '.', '<STOP>'], 'tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], '__index_level_0__': 2265}\n",
      "(tensor([[    4,  2208,   643,     8,   737,  1122,  2052,    22,    27,  2482,\n",
      "            10,     8, 39256,    44,     4,  1122,  2052,    20,    14,  5727,\n",
      "           737,    22,     8,   290,  4628,  9573,  4943,    27,  2482,    10,\n",
      "             8, 39256,     9,  1122,    29,  1622,    12,     8,   239,    22,\n",
      "           405,   236,     7,  3082,     7,    10,    50,   114,  8297,    32,\n",
      "          7683, 11575,   514,   154,     9,   559,   127,   505, 11199,  1122,\n",
      "            29,    14,     4,   823,  2039,     4,     7,    74,    66,    14,\n",
      "          8322,    24, 17402,  9608,    19, 23205,  1456,  2157,    17,     7,\n",
      "           988,    91,    55, 31702,     9,    27,  1391,  2455,  1764,     7,\n",
      "            54,     8,   112,    43,  1868,   915,   154,     9,   455,    14,\n",
      "           151,    22,     8,   414,     7,  4321,   902,     8,   737,    14,\n",
      "          1590, 30981,     7,  5621,    10,   256,     9,   138,   416,    49,\n",
      "         20403, 10219,  2886, 23058,  2052,    19, 19979, 60821,    17,     9,\n",
      "           455,    14,  1578,  1591,    12,   550,  7556,    19, 15653, 64180,\n",
      "            17,     4,   902,  1917,    12,    49,  1749, 11442,  7556,    19,\n",
      "          6715, 32827,    17,     4,  1472,  1111,  1122,    31,   959,    25,\n",
      "            14,   864, 10957,     7,    25,   229,    25,    49,  1391,    10,\n",
      "          9946,  1591,    12,    10,   246,  5042,    33, 10677, 59431,    19,\n",
      "         21985, 48863,    17,     9,  1122,    31,  4595,    11,  8946, 31412,\n",
      "            24,     4,    49, 32981, 13179, 14363,  2366,    19, 57304, 18787,\n",
      "            17,     7,    10, 24978, 40894,    19, 12427, 59178,    17,     7,\n",
      "             8,  1306,    11,    51,    11,    49,     4,     9,  3395,     8,\n",
      "           155,     7,  1122,  1079,    12,   802,  4315,   892,    13,   638,\n",
      "         20871,    25,    14,   864, 10957,     9,     4]]), tensor([237]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "print(X_val[0])\n",
    "print(collate_batch_bilstm([X_val[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic BiLSTM-CRF network\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_embeddings: torch.tensor,\n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1,\n",
    "            n_classes: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializer for basic BiLSTM network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained BPE embeddings\n",
    "        :param lstm_dim: The dimensionality of the BiLSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        :param n_classes: The number of output classes\n",
    "        \"\"\"\n",
    "\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "\n",
    "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
    "        # The components are an embedding layer, a 2 layer BiLSTM, and a feed-forward output layer\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
    "            'bilstm': nn.LSTM(\n",
    "                pretrained_embeddings.shape[1],\n",
    "                lstm_dim,\n",
    "                2,\n",
    "                batch_first=True,\n",
    "                dropout=dropout_prob,\n",
    "                bidirectional=True),\n",
    "            'ff': nn.Linear(2*lstm_dim, n_classes),\n",
    "            'CRF': CRF(n_classes, batch_first=True)\n",
    "        })\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Initialize the weights of the model\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['bilstm'].named_parameters()) + \\\n",
    "                     list(self.model['ff'].named_parameters())\n",
    "        for n,p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "    def forward(self, inputs, input_lens, labels = None):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :param labels: (b) The label of each sample\n",
    "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings (b x sl x edim)\n",
    "        embeds = self.model['embeddings'](inputs)\n",
    "\n",
    "        # Pack padded: This is necessary for padded batches input to an RNN\n",
    "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
    "            embeds,\n",
    "            input_lens.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # Pass the packed sequence through the BiLSTM\n",
    "        lstm_out, hidden = self.model['bilstm'](lstm_in)\n",
    "\n",
    "        # Unpack the packed sequence --> (b x sl x 2*lstm_dim)\n",
    "        lstm_out,_ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        # Get emissions (b x seq_len x n_classes)\n",
    "        emissions = self.model['ff'](lstm_out)\n",
    "        outputs = (emissions,)\n",
    "        if labels is not None:\n",
    "            mask = (inputs != 0)\n",
    "            # log-likelihood from the CRF\n",
    "            log_likelihood = self.model['CRF'](emissions, labels, mask=mask, reduction='token_mean')\n",
    "            outputs = (-log_likelihood,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def decode(self, emissions, mask):\n",
    "        \"\"\"\n",
    "        Given a set of emissions and a mask, decode the sequence\n",
    "        \"\"\"\n",
    "        return self.model['CRF'].decode(emissions, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module, \n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    n_epochs: int, \n",
    "    device: torch.device,\n",
    "    scheduler=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    The main training loop which will optimize a given model on a given dataset\n",
    "    :param model: The model being optimized\n",
    "    :param train_dl: The training dataset\n",
    "    :param valid_dl: A validation dataset\n",
    "    :param optimizer: The optimizer used to update the model parameters\n",
    "    :param n_epochs: Number of epochs to train for\n",
    "    :param device: The device to train on\n",
    "    :return: (model, losses) The best model and the losses per iteration\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep track of the loss and best accuracy\n",
    "    losses = []\n",
    "    learning_rates = []\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    # Iterate through epochs\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        loss_epoch = []\n",
    "\n",
    "        #Iterate through each batch in the dataloader\n",
    "        for batch in tqdm(train_dl):\n",
    "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
    "            # things like dropout and layer normalization\n",
    "            model.train()\n",
    "\n",
    "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
    "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
    "            # zero them out\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Place each tensor on the GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            seq_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            # Pass the inputs through the model, get the current loss and logits\n",
    "            loss, logits = model(input_ids, seq_lens, labels=labels)\n",
    "            losses.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "            # Calculate all of the gradients and weight updates for the model\n",
    "            loss.backward()\n",
    "\n",
    "            # Optional: clip gradients\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Finally, update the weights of the model\n",
    "            optimizer.step()\n",
    "            if scheduler != None:\n",
    "                scheduler.step()\n",
    "                learning_rates.append(scheduler.get_last_lr()[0])\n",
    "\n",
    "        #gc.collect()\n",
    "\n",
    "        # Perform inline evaluation at the end of the epoch\n",
    "        f1 = evaluate(model, valid_dl)\n",
    "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
    "\n",
    "        # Keep track of the best model based on the accuracy\n",
    "        if f1 > best_f1:\n",
    "            torch.save(model.state_dict(), 'best_model')\n",
    "            best_f1 = f1\n",
    "            #gc.collect()\n",
    "\n",
    "    return losses, learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, valid_dl: DataLoader):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given dataset\n",
    "    :param model: The model under evaluation\n",
    "    :param valid_dl: A `DataLoader` reading validation data\n",
    "    :return: The accuracy of the model on the dataset\n",
    "    \"\"\"\n",
    "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like \n",
    "    # layer normalization and dropout\n",
    "    model.eval()\n",
    "    labels_all = []\n",
    "    logits_all = []\n",
    "    tags_all = []\n",
    "\n",
    "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            seq_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            logits = model(input_ids, seq_lens, labels=labels)[-1]\n",
    "            mask = (input_ids != 0)\n",
    "            labels_all.extend([l for seq,samp in zip(list(labels.detach().cpu().numpy()), input_ids) for l,i in zip(seq,samp) if i != 0])\n",
    "            logits_all.extend(list(logits.detach().cpu().numpy()))\n",
    "\n",
    "            tags = model.decode(logits, mask)\n",
    "            tags_all.extend([t for seq in tags for t in seq])\n",
    "\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, tags_all, average='macro')\n",
    "    print(confusion_matrix(labels_all, tags_all))\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dim = 128\n",
    "dropout_prob = 0.1\n",
    "batch_size = 8\n",
    "lr = 1e-2\n",
    "n_epochs = 1\n",
    "n_workers = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "# Create the model\n",
    "model = BiLSTM_CRF(\n",
    "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
    "    lstm_dim=lstm_dim, \n",
    "    dropout_prob=dropout_prob, \n",
    "    n_classes=3\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1019c00bdd714b819455b7735b5879b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/838 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e371111f8147aab64dbc2937668847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[204481      0    457]\n",
      " [  2981      0      0]\n",
      " [  1037      0    639]]\n",
      "Validation F1: 0.48340502094641175, train loss: 0.06683511207733739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(X_train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "valid_dl = DataLoader(X_val, batch_size=len(X_val), collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_dl)*n_epochs, cycle_momentum=False)\n",
    "\n",
    "# Train\n",
    "losses, learning_rates = train(model, train_dl, valid_dl, optimizer, n_epochs, device, scheduler)\n",
    "model.load_state_dict(torch.load('best_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Encoder model.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "            pretrained_embeddings: torch.tensor, \n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initializer for EncoderRNN network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
    "        :param lstm_dim: The dimensionality of the LSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        \"\"\"\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
    "        # The components are an embedding layer, and an LSTM layer.\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
    "            'lstm': nn.LSTM(pretrained_embeddings.shape[1], lstm_dim, 2, batch_first=True, bidirectional=True),\n",
    "        })\n",
    "        # Initialize the weights of the model\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['lstm'].named_parameters())\n",
    "        for n, p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "    def forward(self, inputs, input_lens):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :return: (lstm output state, lstm hidden state) \n",
    "        \"\"\"\n",
    "        embeds = self.model['embeddings'](inputs)\n",
    "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
    "                    embeds,\n",
    "                    input_lens.cpu(),\n",
    "                    batch_first=True,\n",
    "                    enforce_sorted=False\n",
    "                )\n",
    "        lstm_out, hidden_states = self.model['lstm'](lstm_in)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        return lstm_out, hidden_states\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN Decoder model.\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_embeddings: torch.tensor, \n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1,\n",
    "            n_classes: int = 2):\n",
    "        \"\"\"\n",
    "        Initializer for DecoderRNN network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
    "        :param lstm_dim: The dimensionality of the LSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        :param n_classes: Number of prediction classes\n",
    "        \"\"\"\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
    "        # The components are an embedding layer, a LSTM layer, and a feed-forward output layer\n",
    "        self.model = nn.ModuleDict({\n",
    "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
    "            'lstm': nn.LSTM(pretrained_embeddings.shape[1], lstm_dim, 2, bidirectional=True, batch_first=True),\n",
    "            'nn': nn.Linear(lstm_dim*2, n_classes),\n",
    "        })\n",
    "        # Initialize the weights of the model\n",
    "        self._init_weights()      \n",
    "\n",
    "    def forward(self, inputs, hidden, input_lens):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param hidden: (b) The hidden state of the previous step\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :return: (output predictions, lstm hidden states) the hidden states will be used as input at the next step\n",
    "        \"\"\"\n",
    "        embeds = self.model['embeddings'](inputs)\n",
    "\n",
    "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
    "                    embeds,\n",
    "                    input_lens.cpu(),\n",
    "                    batch_first=True,\n",
    "                    enforce_sorted=False\n",
    "                )\n",
    "        lstm_out, hidden_states = self.model['lstm'](lstm_in, hidden)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
    "        output = self.model['nn'](lstm_out)\n",
    "        return output, hidden_states\n",
    "\n",
    "    def _init_weights(self):\n",
    "        all_params = list(self.model['lstm'].named_parameters()) + list(self.model['nn'].named_parameters())\n",
    "        for n, p in all_params:\n",
    "            if 'weight' in n:\n",
    "                nn.init.xavier_normal_(p)\n",
    "            elif 'bias' in n:\n",
    "                nn.init.zeros_(p)\n",
    "\n",
    "# Define the model\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Seq2Seq network\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            pretrained_embeddings: torch.tensor,\n",
    "            lstm_dim: int,\n",
    "            dropout_prob: float = 0.1,\n",
    "            n_classes: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializer for basic Seq2Seq network\n",
    "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
    "        :param lstm_dim: The dimensionality of the LSTM network\n",
    "        :param dropout_prob: Dropout probability\n",
    "        :param n_classes: The number of output classes\n",
    "        \"\"\"\n",
    "\n",
    "        # First thing is to call the superclass initializer\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        # We'll define the network in a ModuleDict, which consists of an encoder and a decoder\n",
    "        self.model = nn.ModuleDict({\n",
    "            'encoder': EncoderRNN(pretrained_embeddings, lstm_dim, dropout_prob),\n",
    "            'decoder': DecoderRNN(pretrained_embeddings, lstm_dim, dropout_prob, n_classes),\n",
    "        })\n",
    "        self.loss = nn.CrossEntropyLoss(weight=torch.FloatTensor([0.5]+[1]*(3-1)).to(device)) # number of classes - 1\n",
    "\n",
    "\n",
    "    def forward(self, inputs, input_lens, labels=None):\n",
    "        \"\"\"\n",
    "        Defines how tensors flow through the model. \n",
    "        For the Seq2Seq model this includes 1) encoding the whole input text, \n",
    "        and running *target_length* decoding steps to predict the tag of each token.\n",
    "\n",
    "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "        :param input_lens: (b) The length of each input sequence\n",
    "        :param labels: (b) The label of each sample\n",
    "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings (b x sl x embedding dim)\n",
    "        encoder_output, encoder_hidden = self.model['encoder'](inputs, input_lens)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = torch.tensor([tokenizer.encode(['[BOS]'])]*inputs.shape[0], device=device)\n",
    "        target_length = labels.size(1)\n",
    "\n",
    "        loss = None\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = self.model['decoder'](\n",
    "                decoder_input, decoder_hidden, torch.tensor([1]*inputs.shape[0]))\n",
    "\n",
    "            if loss == None:   \n",
    "                loss = self.loss(decoder_output.squeeze(1), labels[:, di])\n",
    "            else:\n",
    "                loss += self.loss(decoder_output.squeeze(1), labels[:, di])\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            decoder_input = labels[:, di].unsqueeze(-1) \n",
    "\n",
    "        return loss / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module, \n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    n_epochs: int, \n",
    "    device: torch.device,\n",
    "):\n",
    "    \"\"\"\n",
    "    The main training loop which will optimize a given model on a given dataset\n",
    "    :param model: The model being optimized\n",
    "    :param train_dl: The training dataset\n",
    "    :param valid_dl: A validation dataset\n",
    "    :param optimizer: The optimizer used to update the model parameters\n",
    "    :param n_epochs: Number of epochs to train for\n",
    "    :param device: The device to train on\n",
    "    :return: (model, losses) The best model and the losses per iteration\n",
    "    \"\"\"\n",
    "\n",
    "    # Keep track of the loss and best accuracy\n",
    "    losses = []\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    # Iterate through epochs\n",
    "    for ep in range(n_epochs):\n",
    "\n",
    "        loss_epoch = []\n",
    "\n",
    "        #Iterate through each batch in the dataloader\n",
    "        for batch in tqdm(train_dl):\n",
    "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
    "            # things like dropout and layer normalization\n",
    "            model.train()\n",
    "\n",
    "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
    "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
    "            # zero them out\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Place each tensor on the GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            labels = batch[2]\n",
    "            input_lens = batch[1]\n",
    "\n",
    "            # Pass the inputs through the model, get the current loss and logits\n",
    "            loss = model(input_ids, labels=labels, input_lens=input_lens)\n",
    "            losses.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "            # Calculate all of the gradients and weight updates for the model\n",
    "            loss.backward()\n",
    "\n",
    "            # Optional: clip gradients\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Finally, update the weights of the model\n",
    "            optimizer.step()\n",
    "\n",
    "        # Perform inline evaluation at the end of the epoch\n",
    "        f1 = evaluate(model, valid_dl)\n",
    "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
    "\n",
    "        # Keep track of the best model based on the accuracy\n",
    "        if f1 > best_f1:\n",
    "            torch.save(model.state_dict(), 'best_model')\n",
    "            best_f1 = f1\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "def decode(model, inputs, input_lens, labels=None, beam_size=2):\n",
    "    \"\"\"\n",
    "    Decoding/predicting the labels for an input text by running beam search.\n",
    "\n",
    "    :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
    "    :param input_lens: (b) The length of each input sequence\n",
    "    :param labels: (b) The label of each sample\n",
    "    :param beam_size: the size of the beam \n",
    "    :return: predicted sequence of labels\n",
    "    \"\"\"\n",
    "\n",
    "    assert inputs.shape[0] == 1\n",
    "    # first, encode the input text\n",
    "    encoder_output, encoder_hidden = model.model['encoder'](inputs, input_lens)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # the decoder starts generating after the Begining of Sentence (BOS) token\n",
    "    decoder_input = torch.tensor([tokenizer.encode(['[BOS]',]),], device=device)\n",
    "    target_length = labels.shape[1]\n",
    "    \n",
    "    # we will use heapq to keep top best sequences so far sorted in heap_queue \n",
    "    # these will be sorted by the first item in the tuple\n",
    "    heap_queue = []\n",
    "    heap_queue.append((torch.tensor(0), tokenizer.encode(['[BOS]']), decoder_input, decoder_hidden))\n",
    "\n",
    "    # Beam Decoding\n",
    "    for _ in range(target_length):\n",
    "        # print(\"next len\")\n",
    "        new_items = []\n",
    "        # for each item on the beam\n",
    "        for j in range(len(heap_queue)): \n",
    "            # 1. remove from heap\n",
    "            score, tokens, decoder_input, decoder_hidden = heapq.heappop(heap_queue)\n",
    "            # 2. decode one more step\n",
    "            decoder_output, decoder_hidden = model.model['decoder'](\n",
    "                decoder_input, decoder_hidden, torch.tensor([1]))\n",
    "            decoder_output = softmax(decoder_output)\n",
    "            # 3. get top-k predictions\n",
    "            best_idx = torch.argsort(decoder_output[0], descending=True)[0]\n",
    "            # print(decoder_output)\n",
    "            # print(best_idx)\n",
    "            for i in range(beam_size):\n",
    "                decoder_input = torch.tensor([[best_idx[i]]], device=device)\n",
    "                \n",
    "                new_items.append((score + decoder_output[0,0, best_idx[i]],\n",
    "                                  tokens + [best_idx[i].item()], \n",
    "                                  decoder_input, \n",
    "                                  decoder_hidden))\n",
    "        # add new sequences to the heap\n",
    "        for item in new_items:\n",
    "          # print(item)\n",
    "            heapq.heappush(heap_queue, item)\n",
    "        # remove sequences with lowest score (items are sorted in descending order)\n",
    "        while len(heap_queue) > beam_size:\n",
    "            heapq.heappop(heap_queue)\n",
    "          \n",
    "    final_sequence = heapq.nlargest(1, heap_queue)[0]\n",
    "    assert labels.shape[1] == len(final_sequence[1][1:])\n",
    "    return final_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, valid_dl: DataLoader, beam_size:int = 1):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given dataset\n",
    "    :param model: The model under evaluation\n",
    "    :param valid_dl: A `DataLoader` reading validation data\n",
    "    :return: The accuracy of the model on the dataset\n",
    "    \"\"\"\n",
    "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like \n",
    "    # layer normalization and dropout\n",
    "    model.eval()\n",
    "    labels_all = []\n",
    "    logits_all = []\n",
    "    tags_all = []\n",
    "\n",
    "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids = batch[0]\n",
    "            input_lens = batch[1]\n",
    "            labels = batch[2]\n",
    "\n",
    "            best_seq = decode(model, input_ids, input_lens, labels=labels, beam_size=beam_size)\n",
    "            mask = (input_ids != 0)\n",
    "            labels_all.extend([l for seq,samp in zip(list(labels.detach().cpu().numpy()), input_ids) for l,i in zip(seq,samp) if i != 0])\n",
    "            tags_all += best_seq[1][1:]\n",
    "            # print(best_seq[1][1:], labels)\n",
    "    P, R, F1, _ = precision_recall_fscore_support(labels_all, tags_all, average='macro')\n",
    "    print(confusion_matrix(labels_all, tags_all))\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dim = 300\n",
    "dropout_prob = 0.1\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "n_epochs = 1\n",
    "n_workers = 0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "# Create the model\n",
    "model = Seq2Seq(\n",
    "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
    "    lstm_dim=lstm_dim, \n",
    "    dropout_prob=dropout_prob, \n",
    "    n_classes=3\n",
    "  ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07a69d1b25b41a099a1feb6c7aca93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf7fb63e9ad4654be7589a76c1918c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/1676 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[204938      0      0]\n",
      " [  2981      0      0]\n",
      " [  1676      0      0]]\n",
      "Validation F1: 0.3295885570831112, train loss: 0.039646620928709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl = DataLoader(X_train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "valid_dl = DataLoader(X_val, batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "losses = train(model, train_dl, valid_dl, optimizer, n_epochs, device)\n",
    "model.load_state_dict(torch.load('best_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3043469588e44cc583f5e694ef6dae57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/6700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[812752      0      0]\n",
      " [ 12976      0      0]\n",
      " [  6700      0      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32934673814820664"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataLoader(X_train, batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
    "evaluate(model, test_dl, beam_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d5e1198a7f463f87b9a5d4e3c4e514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/6700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_10237/724389592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_10237/2807781268.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, valid_dl, beam_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mbest_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mlabels_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_10237/3377331845.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, inputs, input_lens, labels, beam_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheappop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheap_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# 2. decode one more step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             decoder_output, decoder_hidden = model.model['decoder'](\n\u001b[0m\u001b[1;32m     38\u001b[0m                 decoder_input, decoder_hidden, torch.tensor([1]))\n\u001b[1;32m     39\u001b[0m             \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/s3/51rzg94s5318dvd1cr9t6cq40000gn/T/ipykernel_10237/4170596066.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, input_lens)\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 )\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    770\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    771\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    773\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    774\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(model, test_dl, beam_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
