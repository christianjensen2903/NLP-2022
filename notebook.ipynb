{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Model import Model\n",
    "from models.GPT2Generator import GPT2Generator\n",
    "from models.Logistic.BOWLogistic import BOWLogistic\n",
    "from models.MLP.BOWMLP import BOWMLP\n",
    "from models.MLP.CBOW_BOWMLP import CBOW_BOWMLP\n",
    "from models.MLP.CBOWMLP import CBOWMLP\n",
    "from models.RandomForest.BOWRandomForest import BOWRandomForest\n",
    "from models.RandomForest.CBOW_BOWRandomForest import CBOW_BOWRandomForest\n",
    "from models.RandomForest.CBOWRandomForest import CBOWRandomForest\n",
    "from models.Logistic.CBOW_BOWLogistic import CBOW_BOWLogistic\n",
    "from models.Logistic.CBOWLogistic import CBOWLogistic\n",
    "from models.XGBoost.BOWXGBoost import BOWXGBoost\n",
    "from models.XGBoost.CBOW_BOWXGBoost import CBOW_BOWXGBoost\n",
    "from models.XGBoost.CBOWXGBoost import CBOWXGBoost\n",
    "\n",
    "from models.SequenceLabeller_BiLSTM_CRF import SequenceLabeller_BiLSTM_CRF\n",
    "from models.SequenceLabeller_BiLSTM_CRF_Beam import SequenceLabeller_BiLSTM_CRF_Beam\n",
    "from models.SequenceLabeller_BERT import SequenceLabeller_BERT\n",
    "\n",
    "\n",
    "from languages.LanguageModel import LanguageModel\n",
    "from DataExploration import DataExploration\n",
    "# from languages.Japanese import Japanese\n",
    "from languages.English import English\n",
    "from languages.Finnish import Finnish\n",
    "from Preprocess import Preprocess\n",
    "from Pipeline import Pipeline\n",
    "from typing import List\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download word_vectors\n",
    "!mkdir word_vectors\n",
    "%cd word_vectors\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ja.300.vec.gz\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fi.300.vec.gz\n",
    "\n",
    "!gzip -d cc.en.300.vec.gz\n",
    "!gzip -d cc.ja.300.vec.gz\n",
    "!gzip -d cc.fi.300.vec.gz\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_reproducibility(seed=42):\n",
    "    # Sets seed manually for both CPU and CUDA\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # For atomic operations there is currently \n",
    "    # no simple way to enforce determinism, as\n",
    "    # the order of parallel operations is not known.\n",
    "    # CUDNN\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # System based\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "enforce_reproducibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is used to minimize the clutter in the console\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "# Define the languages to be used\n",
    "languages: List[LanguageModel] = [\n",
    "    English(),\n",
    "    Finnish(),\n",
    "    #Japanese()\n",
    "]\n",
    "\n",
    "# gpt2Generator = GPT2Generator()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_headline(language: str):\n",
    "    print(f'\\n\\n--- Language: {language} ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "for language in languages:\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    # Get the preprocessed data and split it into training and validation data\n",
    "    preprocessor = Preprocess(language.tokenize, language.clean)\n",
    "    data = pipeline.get_data(language=language.name, preproccesor=preprocessor)\n",
    "    train_data, validation_data = pipeline.split_data(data)\n",
    "\n",
    "    all_data[language.name] = {\n",
    "        \"train_data\": train_data,\n",
    "        \"validation_data\": validation_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data for each language\n",
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "    data_exploration = DataExploration(all_data[language.name][\"train_data\"])\n",
    "    data_exploration.find_frequent_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Question Classification\n",
    "Binary classfiers that only takes features based on the question, context document and combinations of the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    feature_based_classifiers = [\n",
    "        BOWRandomForest(language.name),\n",
    "        BOWMLP(language.name),\n",
    "        BOWLogistic(language.name),\n",
    "        BOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Learning\n",
    "Extension of our binary question classifers to also include features based on continous vector representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    continous_based_classifiers = [\n",
    "        CBOW_BOWRandomForest(language.name),\n",
    "        CBOW_BOWMLP(language.name),\n",
    "        CBOW_BOWLogistic(language.name),\n",
    "        CBOW_BOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also test how the performance if only the continous representations was to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    continous_based_classifiers = [\n",
    "        CBOWRandomForest(language.name),\n",
    "        CBOWMLP(language.name),\n",
    "        CBOWLogistic(language.name),\n",
    "        CBOWXGBoost(language.name)\n",
    "    ]\n",
    "    \n",
    "    for classifier in feature_based_classifiers:\n",
    "        print(f'--- Classifier: {classifier.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(train_data),\n",
    "            y=classifier.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=classifier,\n",
    "            X=classifier.extract_X(validation_data),\n",
    "            y=classifier.extract_y(validation_data)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modelling\n",
    "Extension to the classifiers in which word/sentence representations are instead extracted from neural language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    classifier = GPT2CBOWLogistic(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(train_data),\n",
    "        y=classifier.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    pipeline.evaluate(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(validation_data),\n",
    "        y=classifier.extract_y(validation_data)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to sample from these language models to see what kinds of sentences they generate. Moreover we measure the performance on the TyDi QA validation data with a commonly used language model evaluations metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_beginning = {\n",
    "    'english': ['When', 'What', 'How'],\n",
    "    'finnish': ['Milloin', 'Mikä', 'Missä'],\n",
    "    'japanese': ['日本', '『', 'アメリカ']\n",
    "}\n",
    "\n",
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    model = GPT2Generator(language.name)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=classifier,\n",
    "        X=classifier.extract_X(train_data),\n",
    "        y=classifier.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    for starting_word in question_beginning[language.name]:\n",
    "        model.generate_text(f'Question: {starting_word}')\n",
    "    model.get_perplexity(model.extract_X(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis and Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the trained models and then we run the explainability method for that nodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models :list[Model] =[\n",
    "  CBOW_BOWLogistic(),\n",
    "  CBOW_BOWRandomForest()\n",
    "]\n",
    "for model in models:\n",
    "  model.set_language(language.name)\n",
    "  model.load()\n",
    "  model.explainability(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adverserial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = English()\n",
    "pipeline = Pipeline()\n",
    "\n",
    "\n",
    "preprocessor = Preprocess(language.tokenize, language.clean)\n",
    "preprocessor.from_datasets = False\n",
    "raw_adversarial_data = {\n",
    "  \"question_text\"      : [\"When was Queen Elizabeth II born?\" , \"What is the name for a male horse?\" , \"What is the name for a male horse?\"],\n",
    "  \"document_plaintext\" : [\n",
    "    \"Queen Elizabeth II was the queen of England from 1952 until she died on the 8th of september 2022.\" ,\n",
    "    \"A horse is frequently referred to as a stallion once he fathers a foal. While in most of the western world stallions are primarily kept for breeding, it is popular in parts of the Middle East and Asia for stallions to be used for riding (almost always by men).\" ,\n",
    "    \"A mare is an adult female horse or other equine. In most cases, a mare is a female horse over the age of three, and a filly is a female horse three and younger. In Thoroughbred horse racing, a mare is defined as a female horse more than four years old. The word can also be used for other female equine animals, particularly mules and zebras, but a female donkey is usually called a 'jenny'. A broodmare is a mare used for breeding. A horse's female parent is known as its dam.\"]\n",
    "}\n",
    "dataset = pd.DataFrame.from_dict(data = raw_adversarial_data)\n",
    "data = preprocessor.preprocess(dataset)\n",
    "\n",
    "\n",
    "models :list[Model] =[\n",
    "  CBOW_BOWLogistic(),\n",
    "  CBOW_BOWRandomForest()\n",
    "]\n",
    "for model in models:\n",
    "  model.set_language(language.name)\n",
    "  model.load()\n",
    "\n",
    "  X_validation = model.extract_X(data)\n",
    "  y_validation = [0,1,0]\n",
    "\n",
    "  pipeline.evaluate(\n",
    "              model,\n",
    "              X_validation,\n",
    "              y_validation\n",
    "          )\n",
    "\n",
    "  print(model.predict(X_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Labelling\n",
    "We implement a sequence labeller, which predicts which parts of a paragraph are likel part of the answer to the corresponding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_train_epochs': 10,\n",
    "    'learning_rate': 2e-5,\n",
    "    'per_device_train_batch_size': 8,\n",
    "    'per_device_eval_batch_size': 8,\n",
    "    'warmup_steps': 200,\n",
    "    'weight_decay': 0.01,\n",
    "    'lstm_dim': 128,\n",
    "    'dropout_prob': 0.1,\n",
    "    'n_workers': 0,\n",
    "    'beam_size': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    sequence_labellers = [\n",
    "        SequenceLabeller_BERT(language.name, config),\n",
    "        SequenceLabeller_BiLSTM_CRF(language.name, config),\n",
    "    ]\n",
    "\n",
    "    for sequence_labeller in sequence_labellers:\n",
    "        print(f'--- Sequence Labeller: {sequence_labeller.__class__.__name__} ---')\n",
    "        train_data = all_data[language.name][\"train_data\"]\n",
    "        validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "        pipeline = Pipeline()\n",
    "        pipeline.train(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(train_data),\n",
    "            y=sequence_labeller.extract_y(train_data)\n",
    "        )\n",
    "\n",
    "        pipeline.evaluate(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(validation_data),\n",
    "            y=sequence_labeller.extract_y(validation_data)\n",
    "        )\n",
    "        sequence_labeller.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an extension to the sequence labeller which uses beam search to select the optimal sequence of labels for the location of the answer in the text. Analyse how the performance of this system differs with beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    print_headline(language.name)\n",
    "\n",
    "    sequence_labeller = SequenceLabeller_BiLSTM_CRF_Beam(language.name, config)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(train_data),\n",
    "        y=sequence_labeller.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    num_beams = [1, 2, 3]\n",
    "\n",
    "    for beam in num_beams:\n",
    "        sequence_labeller.beam_size = beam\n",
    "        pipeline.evaluate(\n",
    "            model=sequence_labeller,\n",
    "            X=sequence_labeller.extract_X(validation_data),\n",
    "            y=sequence_labeller.extract_y(validation_data)\n",
    "        )\n",
    "    \n",
    "    sequence_labeller.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative investigation of the predicted answer spans\n",
    "transformers.logging.set_verbosity_error()\n",
    "sequence_labeller = SequenceLabeller_BERT('english', config)\n",
    "sequence_labeller.load()\n",
    "\n",
    "validation_data = all_data['english'][\"validation_data\"]\n",
    "\n",
    "for i in range(10):\n",
    "    i += 10 # plus 10 due to the first 10 examples being mostly withouth answer\n",
    "    row = validation_data.iloc[[i]]\n",
    "    X = sequence_labeller.extract_X(row)\n",
    "\n",
    "    predictions = sequence_labeller.predict(X)[0] # [0] because we only have one example\n",
    "\n",
    "    predicted_answers = ['']\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "\n",
    "        predicted_label = predictions[i]\n",
    "        if predicted_label == 'B' or predicted_label == 'I': # if the label is B or I, we add the token to the current answer\n",
    "            predicted_answers[-1] += row['tokenized_plaintext'].values[0][i] + ' '\n",
    "\n",
    "        elif predicted_label == 'O' and predicted_answers[-1] != '': # if the label is O and the current answer is not empty, we add a new answer\n",
    "            predicted_answers[-1] = predicted_answers[-1][:-1] # remove trailing space\n",
    "            predicted_answers.append('')\n",
    "\n",
    "    if predicted_answers[-1] == '': # remove last empty answer\n",
    "        predicted_answers = predicted_answers[:-1]\n",
    "\n",
    "\n",
    "    print(f'Question: {row[\"question_text\"].values[0]}')\n",
    "    print(f'Answer: {row[\"answer_text\"].values[0]}')\n",
    "    print(f'Predicted answers: {predicted_answers}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by implementing our binary question system with a multilingual encoder instead of the monolingual ones. With this we perform zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutli-lingual binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now implement our sequence tagger with a multilingual encoding and perform zero-shot cross-lingual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero shot classification\n",
    "for language in languages:\n",
    "    print(f'\\n\\n--- Training on {language.name} ---')\n",
    "\n",
    "    sequence_labeller = SequenceLabeller_BERT('multilingual', config)\n",
    "\n",
    "    train_data = all_data[language.name][\"train_data\"]\n",
    "    validation_data = all_data[language.name][\"validation_data\"]\n",
    "\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.train(\n",
    "        model=sequence_labeller,\n",
    "        X=sequence_labeller.extract_X(train_data),\n",
    "        y=sequence_labeller.extract_y(train_data)\n",
    "    )\n",
    "\n",
    "    for language in languages:\n",
    "      print(f'--- Validating on {language.name} ---')\n",
    "      validation_data = all_data[language.name]['validation_data']\n",
    "      pipeline.evaluate(\n",
    "          model=sequence_labeller,\n",
    "          X=sequence_labeller.extract_X(validation_data),\n",
    "          y=sequence_labeller.extract_y(validation_data)\n",
    "      )\n",
    "    \n",
    "    sequence_labeller.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf259275ad4a72d4dd5b452264ad5fb2b635233dff2a31edc6ebc740e55e21b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
